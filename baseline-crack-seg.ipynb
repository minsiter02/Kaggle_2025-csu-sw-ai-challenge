{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-13T11:26:07.826822Z",
     "iopub.status.busy": "2025-10-13T11:26:07.826549Z",
     "iopub.status.idle": "2025-10-13T11:27:16.075877Z",
     "shell.execute_reply": "2025-10-13T11:27:16.074947Z",
     "shell.execute_reply.started": "2025-10-13T11:26:07.826801Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install -q ptflops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:16.077527Z",
     "iopub.status.busy": "2025-10-13T11:27:16.077295Z",
     "iopub.status.idle": "2025-10-13T11:27:22.548576Z",
     "shell.execute_reply": "2025-10-13T11:27:22.548015Z",
     "shell.execute_reply.started": "2025-10-13T11:27:16.077501Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import jaccard_score\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ê¸°ë³¸ ë””ë ‰í† ë¦¬ ì„¤ì • \n",
    "# TRAIN_DIR = \"/kaggle/input/2025-sw-ai/archive/train\"\n",
    "# VAL_DIR = \"/kaggle/input/2025-sw-ai/archive/val\"\n",
    "# TEST_DIR = \"/kaggle/input/2025-sw-ai/archive/test/images\"\n",
    "# OUTPUT_PATH = \"/kaggle/working/submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¡œì»¬ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "TRAIN_DIR = \"input/2025-csu-sw-ai-challenge/archive/train\" \n",
    "VAL_DIR = \"input/2025-csu-sw-ai-challenge/archive/val\"\n",
    "TEST_DIR = \"input/2025-csu-sw-ai-challenge/archive/test/images\"\n",
    "OUTPUT_PATH = \"working/submission.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.549403Z",
     "iopub.status.busy": "2025-10-13T11:27:22.549145Z",
     "iopub.status.idle": "2025-10-13T11:27:22.555503Z",
     "shell.execute_reply": "2025-10-13T11:27:22.554811Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.549387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CrackDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.img_dir = os.path.join(root_dir, \"images\")\n",
    "        self.mask_dir = os.path.join(root_dir, \"masks\")\n",
    "        self.img_list = sorted(glob.glob(self.img_dir + \"/*.jpg\"))\n",
    "        self.mask_list = sorted(glob.glob(self.mask_dir + \"/*.jpg\"))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.img_list[idx]).convert(\"L\")  # grayscale\n",
    "        mask = Image.open(self.mask_list[idx]).convert(\"L\")\n",
    "\n",
    "        img = np.array(img, dtype=np.float32) / 255.0\n",
    "        mask = np.array(mask, dtype=np.float32) / 255.0\n",
    "        mask = (mask > 0.5).astype(np.float32)  # binary mask\n",
    "\n",
    "        img = torch.tensor(img).unsqueeze(0)  # (1, H, W)\n",
    "        mask = torch.tensor(mask).unsqueeze(0)  # (1, H, W)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.557199Z",
     "iopub.status.busy": "2025-10-13T11:27:22.556966Z",
     "iopub.status.idle": "2025-10-13T11:27:22.580819Z",
     "shell.execute_reply": "2025-10-13T11:27:22.580155Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.557184Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HrSegNetB16(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=1,  # input channel\n",
    "                 base=16,  # base channel of the model, \n",
    "                 num_classes=1,  # number of classes\n",
    "                 pretrained=None  # pretrained model\n",
    "                 ):\n",
    "        super(HrSegNetB16, self).__init__()\n",
    "        self.base = base\n",
    "        self.num_classes = num_classes\n",
    "        self.pretrained = pretrained\n",
    "        # Stage 1 and 2 constitute the stem of the model, which is mainly used to extract low-level features.\n",
    "        # Meanwhile, stage1 and 2 reduce the input image to 1/2 and 1/4 of the original size respectively\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=base // 2, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(base // 2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.stage2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base // 2, out_channels=base, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(base),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.seg1 = SegBlock(base=base, stage_index=1)\n",
    "        self.seg2 = SegBlock(base=base, stage_index=2)\n",
    "        self.seg3 = SegBlock(base=base, stage_index=3)\n",
    "\n",
    "        self.aux_head1 = SegHead(inplanes=base, interplanes=base, outplanes=num_classes, aux_head=True)\n",
    "        self.aux_head2 = SegHead(inplanes=base, interplanes=base, outplanes=num_classes, aux_head=True)\n",
    "        self.head = SegHead(inplanes=base, interplanes=base, outplanes=num_classes)\n",
    "\n",
    "        self.init_weight()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logit_list = []\n",
    "        h, w = x.shape[2:]\n",
    "        # aux_head only used in training\n",
    "        if self.training:\n",
    "            stem1_out = self.stage1(x)\n",
    "            stem2_out = self.stage2(stem1_out)\n",
    "            hrseg1_out = self.seg1(stem2_out)\n",
    "            hrseg2_out = self.seg2(hrseg1_out)\n",
    "            hrseg3_out = self.seg3(hrseg2_out)\n",
    "            last_out = self.head(hrseg3_out)\n",
    "            seghead1_out = self.aux_head1(hrseg1_out)\n",
    "            seghead2_out = self.aux_head2(hrseg2_out)\n",
    "            logit_list = [last_out, seghead1_out, seghead2_out]\n",
    "            logit_list = [F.interpolate(logit, size=(h, w), mode='bilinear', align_corners=True) for logit in logit_list]\n",
    "            return logit_list\n",
    "        else:\n",
    "            stem1_out = self.stage1(x)\n",
    "            stem2_out = self.stage2(stem1_out)\n",
    "            hrseg1_out = self.seg1(stem2_out)\n",
    "            hrseg2_out = self.seg2(hrseg1_out)\n",
    "            hrseg3_out = self.seg3(hrseg2_out)\n",
    "            last_out = self.head(hrseg3_out)\n",
    "            logit_list = [last_out]\n",
    "            logit_list = [F.interpolate(logit, size=(h, w), mode='bilinear', align_corners=True) for logit in logit_list]\n",
    "            return logit_list\n",
    "        \n",
    "    \n",
    "    def init_weight(self):\n",
    "        if self.pretrained is not None:\n",
    "            pass\n",
    "        else:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    nn.init.kaiming_normal_(m.weight)\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "class SegBlock(nn.Module):\n",
    "    def __init__(self, base=32, stage_index=1):\n",
    "        super(SegBlock, self).__init__()\n",
    "\n",
    "        # Convolutional layer for high-resolution paths with constant spatial resolution and constant channel\n",
    "        self.h_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base, out_channels=base, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.h_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base, out_channels=base, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.h_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base, out_channels=base, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Semantic guidance path/low-resolution path\n",
    "        if stage_index == 1:  # First stage, stride=2, spatial resolution/2, channel*2\n",
    "            self.l_conv1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=base, out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        elif stage_index == 2:  # Second stage\n",
    "            self.l_conv1 = nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                nn.Conv2d(in_channels=base, out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        elif stage_index == 3:\n",
    "            self.l_conv1 = nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                nn.Conv2d(in_channels=base, out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"stage_index must be 1, 2 or 3\")\n",
    "        self.l_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.l2h_conv1 = nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base, kernel_size=1, stride=1, padding=0)\n",
    "        self.l2h_conv2 = nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base, kernel_size=1, stride=1, padding=0)\n",
    "        self.l2h_conv3 = nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        size = x.shape[2:]\n",
    "        out_h1 = self.h_conv1(x)  # high resolution path\n",
    "        out_l1 = self.l_conv1(x)  # low resolution path\n",
    "        out_l1_i = F.interpolate(out_l1, size=size, mode='bilinear', align_corners=True)  # upsample\n",
    "        out_hl1 = self.l2h_conv1(out_l1_i) + out_h1  # low to high\n",
    "\n",
    "        out_h2 = self.h_conv2(out_hl1)\n",
    "        out_l2 = self.l_conv2(out_l1)\n",
    "        out_l2_i = F.interpolate(out_l2, size=size, mode='bilinear', align_corners=True)\n",
    "        out_hl2 = self.l2h_conv2(out_l2_i) + out_h2\n",
    "\n",
    "        out_h3 = self.h_conv3(out_hl2)\n",
    "        out_l3 = self.l_conv3(out_l2)\n",
    "        out_l3_i = F.interpolate(out_l3, size=size, mode='bilinear', align_corners=True)\n",
    "        out_hl3 = self.l2h_conv3(out_l3_i) + out_h3\n",
    "        return out_hl3\n",
    "\n",
    "# seg head\n",
    "class SegHead(nn.Module):\n",
    "    def __init__(self, inplanes, interplanes, outplanes, aux_head=False):\n",
    "        super(SegHead, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.relu = nn.ReLU()\n",
    "        if aux_head:\n",
    "            self.con_bn_relu = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=inplanes, out_channels=interplanes, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(interplanes),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        else:\n",
    "            self.con_bn_relu = nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels=inplanes, out_channels=interplanes, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.BatchNorm2d(interplanes),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        self.conv = nn.Conv2d(in_channels=interplanes, out_channels=outplanes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.con_bn_relu(x)\n",
    "        out = self.conv(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.581758Z",
     "iopub.status.busy": "2025-10-13T11:27:22.581581Z",
     "iopub.status.idle": "2025-10-13T11:27:22.596935Z",
     "shell.execute_reply": "2025-10-13T11:27:22.596301Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.581742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def binary_metrics(preds, targets, eps=1e-6):\n",
    "    preds = preds.float()\n",
    "    targets = targets.float()\n",
    "\n",
    "    tp = (preds * targets).sum(dim=(1,2,3))\n",
    "    fp = (preds * (1 - targets)).sum(dim=(1,2,3))\n",
    "    fn = ((1 - preds) * targets).sum(dim=(1,2,3))\n",
    "\n",
    "    precision = (tp + eps) / (tp + fp + eps)\n",
    "    recall    = (tp + eps) / (tp + fn + eps)\n",
    "    f1        = (2 * precision * recall + eps) / (precision + recall + eps)  # Dice\n",
    "    union     = tp + fp + fn\n",
    "    iou       = (tp + eps) / (union + eps)\n",
    "\n",
    "    return {\n",
    "        \"iou\": iou.mean().item(),\n",
    "        \"precision\": precision.mean().item(),\n",
    "        \"recall\": recall.mean().item(),\n",
    "        \"f1\": f1.mean().item(),\n",
    "    }\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    epochs=10,\n",
    "    aux_weights=(1.0, 0.4, 0.4),\n",
    "    lr=1e-3,\n",
    "    use_amp=False,\n",
    "    log_every=500,\n",
    "    validate_every_steps=None,\n",
    "    threshold=0.5,):   \n",
    "    \n",
    "    model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "    global_step = 0\n",
    "    win_loss, win_iou, win_f1, win_steps = 0.0, 0.0, 0.0, 0\n",
    "    t0 = time.time()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for imgs, masks in train_loader:\n",
    "            global_step += 1\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            masks = masks.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                outputs = model(imgs)  # train: [main, aux1, aux2]\n",
    "                main_logit = outputs[0] if isinstance(outputs, (list, tuple)) else outputs\n",
    "                loss = aux_weights[0] * criterion(main_logit, masks)\n",
    "                if isinstance(outputs, (list, tuple)):\n",
    "                    if len(outputs) > 1 and aux_weights[1] > 0:\n",
    "                        loss = loss + aux_weights[1] * criterion(outputs[1], masks)\n",
    "                    if len(outputs) > 2 and aux_weights[2] > 0:\n",
    "                        loss = loss + aux_weights[2] * criterion(outputs[2], masks)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # ì§‘ê³„\n",
    "            epoch_loss += loss.item()\n",
    "            win_loss += loss.item()\n",
    "            win_steps += 1\n",
    "\n",
    "            with torch.no_grad():\n",
    "                probs = torch.sigmoid(main_logit)\n",
    "                preds = (probs > threshold).float()\n",
    "                m = binary_metrics(preds, masks)\n",
    "                win_iou += m[\"iou\"]\n",
    "                win_f1  += m[\"f1\"]\n",
    "\n",
    "            if log_every and (global_step % log_every == 0):\n",
    "                elapsed = time.time() - t0\n",
    "                lr_now = optimizer.param_groups[0][\"lr\"]\n",
    "                print(f\"[Step {global_step}] epoch={epoch}  \"\n",
    "                      f\"avg_loss(win)={win_loss/max(1,win_steps):.4f}  \"\n",
    "                      f\"avg_iou(win)={win_iou/max(1,win_steps):.4f}  \"\n",
    "                      f\"avg_f1(win)={win_f1/max(1,win_steps):.4f}  \"\n",
    "                      f\"lr={lr_now:.3e}  elapsed={elapsed:.1f}s\")\n",
    "                win_loss = win_iou = win_f1 = 0.0\n",
    "                win_steps = 0\n",
    "                t0 = time.time()\n",
    "\n",
    "            if validate_every_steps and (global_step % validate_every_steps == 0):\n",
    "                model.eval()\n",
    "                val_iou_list, val_f1_list = [], []\n",
    "                with torch.no_grad():\n",
    "                    for v_imgs, v_masks in val_loader:\n",
    "                        v_imgs = v_imgs.to(device, non_blocking=True)\n",
    "                        v_masks = v_masks.to(device, non_blocking=True)\n",
    "                        out_list = model(v_imgs)   # eval: [main]ë§Œ\n",
    "                        main_logit_eval = out_list[0] if isinstance(out_list, (list, tuple)) else out_list\n",
    "                        preds = (torch.sigmoid(main_logit_eval) > threshold).float()\n",
    "                        m = binary_metrics(preds, v_masks)\n",
    "                        val_iou_list.append(m[\"iou\"])\n",
    "                        val_f1_list.append(m[\"f1\"])\n",
    "                print(f\"[Step {global_step}] ðŸ” Val IoU={np.mean(val_iou_list):.4f} | Val F1={np.mean(val_f1_list):.4f}\")\n",
    "                model.train()\n",
    "\n",
    "        avg_train_loss = epoch_loss / max(1, len(train_loader))\n",
    "        model.eval()\n",
    "        val_iou_list, val_f1_list = [], []\n",
    "        with torch.no_grad():\n",
    "            for imgs, masks in val_loader:\n",
    "                imgs = imgs.to(device, non_blocking=True)\n",
    "                masks = masks.to(device, non_blocking=True)\n",
    "                logits_list = model(imgs)  # eval: [main]\n",
    "                main_logit = logits_list[0] if isinstance(logits_list, (list, tuple)) else logits_list\n",
    "                preds = (torch.sigmoid(main_logit) > threshold).float()\n",
    "                m = binary_metrics(preds, masks)\n",
    "                val_iou_list.append(m[\"iou\"])\n",
    "                val_f1_list.append(m[\"f1\"])\n",
    "        print(f\"[Epoch {epoch}/{epochs}] \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "              f\"Val IoU: {np.mean(val_iou_list):.4f} | \"\n",
    "              f\"Val F1: {np.mean(val_f1_list):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.597755Z",
     "iopub.status.busy": "2025-10-13T11:27:22.597539Z",
     "iopub.status.idle": "2025-10-13T11:27:22.853695Z",
     "shell.execute_reply": "2025-10-13T11:27:22.853224Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.597730Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = CrackDataset(TRAIN_DIR)\n",
    "val_dataset = CrackDataset(VAL_DIR)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.854526Z",
     "iopub.status.busy": "2025-10-13T11:27:22.854362Z",
     "iopub.status.idle": "2025-10-13T11:27:27.325732Z",
     "shell.execute_reply": "2025-10-13T11:27:27.324895Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.854513Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 609.75 k\n",
      "Total MACs: 130.86 MMac\n"
     ]
    }
   ],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HrSegNetB16().to(device)\n",
    "input_size = (1, 192, 192)\n",
    "\n",
    "macs, params = get_model_complexity_info(model,\n",
    "                                         input_size,\n",
    "                                         as_strings=True,\n",
    "                                         print_per_layer_stat=False,\n",
    "                                         verbose=False)\n",
    "print(f\"Total Params: {params}\")\n",
    "print(f\"Total MACs: {macs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:27.326740Z",
     "iopub.status.busy": "2025-10-13T11:27:27.326532Z",
     "iopub.status.idle": "2025-10-13T11:40:59.805475Z",
     "shell.execute_reply": "2025-10-13T11:40:59.804776Z",
     "shell.execute_reply.started": "2025-10-13T11:27:27.326723Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40006/3727572993.py:38: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
      "/tmp/ipykernel_40006/3727572993.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 500] epoch=1  avg_loss(win)=0.4988  avg_iou(win)=0.0965  avg_f1(win)=0.2051  lr=1.000e-03  elapsed=11.9s\n",
      "[Epoch 1/20] Train Loss: 0.3652 | Val IoU: 0.1558 | Val F1: 0.2105\n",
      "[Step 1000] epoch=2  avg_loss(win)=0.2115  avg_iou(win)=0.2043  avg_f1(win)=0.3239  lr=1.000e-03  elapsed=13.7s\n",
      "[Step 1500] epoch=2  avg_loss(win)=0.1779  avg_iou(win)=0.3007  avg_f1(win)=0.4174  lr=1.000e-03  elapsed=12.5s\n",
      "[Epoch 2/20] Train Loss: 0.1751 | Val IoU: 0.3906 | Val F1: 0.5118\n",
      "[Step 2000] epoch=3  avg_loss(win)=0.1660  avg_iou(win)=0.3342  avg_f1(win)=0.4577  lr=1.000e-03  elapsed=13.2s\n",
      "[Step 2500] epoch=3  avg_loss(win)=0.1568  avg_iou(win)=0.3699  avg_f1(win)=0.4980  lr=1.000e-03  elapsed=12.0s\n",
      "[Epoch 3/20] Train Loss: 0.1557 | Val IoU: 0.4070 | Val F1: 0.5334\n",
      "[Step 3000] epoch=4  avg_loss(win)=0.1529  avg_iou(win)=0.3785  avg_f1(win)=0.5050  lr=1.000e-03  elapsed=13.0s\n",
      "[Step 3500] epoch=4  avg_loss(win)=0.1461  avg_iou(win)=0.4010  avg_f1(win)=0.5296  lr=1.000e-03  elapsed=11.4s\n",
      "[Epoch 4/20] Train Loss: 0.1462 | Val IoU: 0.4471 | Val F1: 0.5635\n",
      "[Step 4000] epoch=5  avg_loss(win)=0.1440  avg_iou(win)=0.4143  avg_f1(win)=0.5415  lr=1.000e-03  elapsed=12.7s\n",
      "[Step 4500] epoch=5  avg_loss(win)=0.1397  avg_iou(win)=0.4214  avg_f1(win)=0.5458  lr=1.000e-03  elapsed=11.6s\n",
      "[Epoch 5/20] Train Loss: 0.1409 | Val IoU: 0.4410 | Val F1: 0.5539\n",
      "[Step 5000] epoch=6  avg_loss(win)=0.1395  avg_iou(win)=0.4211  avg_f1(win)=0.5441  lr=1.000e-03  elapsed=12.5s\n",
      "[Step 5500] epoch=6  avg_loss(win)=0.1350  avg_iou(win)=0.4327  avg_f1(win)=0.5571  lr=1.000e-03  elapsed=10.8s\n",
      "[Epoch 6/20] Train Loss: 0.1370 | Val IoU: 0.4480 | Val F1: 0.5753\n",
      "[Step 6000] epoch=7  avg_loss(win)=0.1360  avg_iou(win)=0.4445  avg_f1(win)=0.5693  lr=1.000e-03  elapsed=12.6s\n",
      "[Step 6500] epoch=7  avg_loss(win)=0.1301  avg_iou(win)=0.4569  avg_f1(win)=0.5807  lr=1.000e-03  elapsed=11.1s\n",
      "[Epoch 7/20] Train Loss: 0.1319 | Val IoU: 0.4616 | Val F1: 0.5848\n",
      "[Step 7000] epoch=8  avg_loss(win)=0.1316  avg_iou(win)=0.4602  avg_f1(win)=0.5870  lr=1.000e-03  elapsed=12.7s\n",
      "[Step 7500] epoch=8  avg_loss(win)=0.1314  avg_iou(win)=0.4530  avg_f1(win)=0.5753  lr=1.000e-03  elapsed=11.0s\n",
      "[Epoch 8/20] Train Loss: 0.1307 | Val IoU: 0.4604 | Val F1: 0.5839\n",
      "[Step 8000] epoch=9  avg_loss(win)=0.1244  avg_iou(win)=0.4736  avg_f1(win)=0.6003  lr=1.000e-03  elapsed=12.7s\n",
      "[Epoch 9/20] Train Loss: 0.1257 | Val IoU: 0.4782 | Val F1: 0.5948\n",
      "[Step 8500] epoch=10  avg_loss(win)=0.1273  avg_iou(win)=0.4744  avg_f1(win)=0.5950  lr=1.000e-03  elapsed=13.3s\n",
      "[Step 9000] epoch=10  avg_loss(win)=0.1256  avg_iou(win)=0.4824  avg_f1(win)=0.6047  lr=1.000e-03  elapsed=10.9s\n",
      "[Epoch 10/20] Train Loss: 0.1242 | Val IoU: 0.5048 | Val F1: 0.6252\n",
      "[Step 9500] epoch=11  avg_loss(win)=0.1232  avg_iou(win)=0.4819  avg_f1(win)=0.6044  lr=1.000e-03  elapsed=12.5s\n",
      "[Step 10000] epoch=11  avg_loss(win)=0.1212  avg_iou(win)=0.4833  avg_f1(win)=0.6031  lr=1.000e-03  elapsed=11.1s\n",
      "[Epoch 11/20] Train Loss: 0.1232 | Val IoU: 0.4812 | Val F1: 0.5984\n",
      "[Step 10500] epoch=12  avg_loss(win)=0.1246  avg_iou(win)=0.4862  avg_f1(win)=0.6112  lr=1.000e-03  elapsed=12.8s\n",
      "[Step 11000] epoch=12  avg_loss(win)=0.1172  avg_iou(win)=0.4990  avg_f1(win)=0.6206  lr=1.000e-03  elapsed=11.0s\n",
      "[Epoch 12/20] Train Loss: 0.1195 | Val IoU: 0.5020 | Val F1: 0.6161\n",
      "[Step 11500] epoch=13  avg_loss(win)=0.1180  avg_iou(win)=0.5087  avg_f1(win)=0.6280  lr=1.000e-03  elapsed=12.7s\n",
      "[Step 12000] epoch=13  avg_loss(win)=0.1182  avg_iou(win)=0.5034  avg_f1(win)=0.6264  lr=1.000e-03  elapsed=11.2s\n",
      "[Epoch 13/20] Train Loss: 0.1172 | Val IoU: 0.5109 | Val F1: 0.6297\n",
      "[Step 12500] epoch=14  avg_loss(win)=0.1177  avg_iou(win)=0.5057  avg_f1(win)=0.6275  lr=1.000e-03  elapsed=13.8s\n",
      "[Step 13000] epoch=14  avg_loss(win)=0.1128  avg_iou(win)=0.5162  avg_f1(win)=0.6387  lr=1.000e-03  elapsed=12.8s\n",
      "[Epoch 14/20] Train Loss: 0.1153 | Val IoU: 0.5060 | Val F1: 0.6246\n",
      "[Step 13500] epoch=15  avg_loss(win)=0.1171  avg_iou(win)=0.5027  avg_f1(win)=0.6258  lr=1.000e-03  elapsed=13.8s\n",
      "[Step 14000] epoch=15  avg_loss(win)=0.1144  avg_iou(win)=0.5157  avg_f1(win)=0.6378  lr=1.000e-03  elapsed=11.3s\n",
      "[Epoch 15/20] Train Loss: 0.1136 | Val IoU: 0.5002 | Val F1: 0.6256\n",
      "[Step 14500] epoch=16  avg_loss(win)=0.1112  avg_iou(win)=0.5197  avg_f1(win)=0.6417  lr=1.000e-03  elapsed=12.5s\n",
      "[Step 15000] epoch=16  avg_loss(win)=0.1134  avg_iou(win)=0.5230  avg_f1(win)=0.6444  lr=1.000e-03  elapsed=10.8s\n",
      "[Epoch 16/20] Train Loss: 0.1125 | Val IoU: 0.5136 | Val F1: 0.6356\n",
      "[Step 15500] epoch=17  avg_loss(win)=0.1104  avg_iou(win)=0.5237  avg_f1(win)=0.6434  lr=1.000e-03  elapsed=12.5s\n",
      "[Step 16000] epoch=17  avg_loss(win)=0.1097  avg_iou(win)=0.5296  avg_f1(win)=0.6500  lr=1.000e-03  elapsed=10.9s\n",
      "[Epoch 17/20] Train Loss: 0.1101 | Val IoU: 0.5285 | Val F1: 0.6511\n",
      "[Step 16500] epoch=18  avg_loss(win)=0.1087  avg_iou(win)=0.5261  avg_f1(win)=0.6475  lr=1.000e-03  elapsed=12.8s\n",
      "[Epoch 18/20] Train Loss: 0.1088 | Val IoU: 0.5194 | Val F1: 0.6420\n",
      "[Step 17000] epoch=19  avg_loss(win)=0.1093  avg_iou(win)=0.5279  avg_f1(win)=0.6499  lr=1.000e-03  elapsed=12.6s\n",
      "[Step 17500] epoch=19  avg_loss(win)=0.1065  avg_iou(win)=0.5344  avg_f1(win)=0.6546  lr=1.000e-03  elapsed=11.0s\n",
      "[Epoch 19/20] Train Loss: 0.1069 | Val IoU: 0.5295 | Val F1: 0.6497\n",
      "[Step 18000] epoch=20  avg_loss(win)=0.1062  avg_iou(win)=0.5447  avg_f1(win)=0.6652  lr=1.000e-03  elapsed=12.4s\n",
      "[Step 18500] epoch=20  avg_loss(win)=0.1032  avg_iou(win)=0.5408  avg_f1(win)=0.6609  lr=1.000e-03  elapsed=11.5s\n",
      "[Epoch 20/20] Train Loss: 0.1055 | Val IoU: 0.5085 | Val F1: 0.6287\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = HrSegNetB16().to(device)\n",
    "train_model(model, train_loader, val_loader, device, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:40:59.806608Z",
     "iopub.status.busy": "2025-10-13T11:40:59.806413Z",
     "iopub.status.idle": "2025-10-13T11:41:00.075814Z",
     "shell.execute_reply": "2025-10-13T11:41:00.075230Z",
     "shell.execute_reply.started": "2025-10-13T11:40:59.806593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def rle_encode(mask):\n",
    "    \"\"\"\n",
    "    mask: 2D numpy array of {0,1}, shape (H,W)\n",
    "    return: run length as string\n",
    "    \"\"\"\n",
    "    pixels = mask.flatten(order=\"C\")\n",
    "    ones = np.where(pixels == 1)[0] + 1  # 1-based\n",
    "    if len(ones) == 0:\n",
    "        return \"\"\n",
    "    runs = []\n",
    "    prev = -2\n",
    "    for idx in ones:\n",
    "        if idx > prev + 1:\n",
    "            runs.extend((idx, 0))\n",
    "        runs[-1] += 1\n",
    "        prev = idx\n",
    "    return \" \".join(map(str, runs))\n",
    "\n",
    "\n",
    "def predict_and_submit(model, test_img_dir, output_csv, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    ids, rles = [], []\n",
    "\n",
    "    test_imgs = sorted(glob.glob(os.path.join(test_img_dir, \"*.jpg\")))\n",
    "    for path in test_imgs:\n",
    "        img_id = os.path.splitext(os.path.basename(path))[0]\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "        arr = np.array(img, dtype=np.float32) / 255.0\n",
    "        tensor = torch.tensor(arr).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out_list = model(tensor)\n",
    "            main_logit = out_list[0] if isinstance(out_list, (list, tuple)) else out_list\n",
    "            prob = torch.sigmoid(main_logit)[0,0].cpu().numpy()\n",
    "            pred = (prob > threshold).astype(np.uint8)\n",
    "\n",
    "        rle = rle_encode(pred)\n",
    "        ids.append(img_id)\n",
    "        rles.append(rle)\n",
    "\n",
    "    df = pd.DataFrame({\"image_id\": ids, \"rle\": rles})\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"[OK] submission saved to {output_csv}, total {len(df)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:41:00.077800Z",
     "iopub.status.busy": "2025-10-13T11:41:00.077387Z",
     "iopub.status.idle": "2025-10-13T11:41:33.222667Z",
     "shell.execute_reply": "2025-10-13T11:41:33.222039Z",
     "shell.execute_reply.started": "2025-10-13T11:41:00.077781Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] submission saved to working/submission.csv, total 2667 rows.\n"
     ]
    }
   ],
   "source": [
    "predict_and_submit(\n",
    "    model, \n",
    "    test_img_dir=TEST_DIR,\n",
    "    output_csv=OUTPUT_PATH,\n",
    "    device=device,\n",
    "    threshold=0.5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13948799,
     "sourceId": 115856,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
