{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-13T11:26:07.826822Z",
     "iopub.status.busy": "2025-10-13T11:26:07.826549Z",
     "iopub.status.idle": "2025-10-13T11:27:16.075877Z",
     "shell.execute_reply": "2025-10-13T11:27:16.074947Z",
     "shell.execute_reply.started": "2025-10-13T11:26:07.826801Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install -q ptflops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:16.077527Z",
     "iopub.status.busy": "2025-10-13T11:27:16.077295Z",
     "iopub.status.idle": "2025-10-13T11:27:22.548576Z",
     "shell.execute_reply": "2025-10-13T11:27:22.548015Z",
     "shell.execute_reply.started": "2025-10-13T11:27:16.077501Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import jaccard_score\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import time\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 기본 디렉토리 설정 \n",
    "# TRAIN_DIR = \"/kaggle/input/2025-sw-ai/archive/train\"\n",
    "# VAL_DIR = \"/kaggle/input/2025-sw-ai/archive/val\"\n",
    "# TEST_DIR = \"/kaggle/input/2025-sw-ai/archive/test/images\"\n",
    "# OUTPUT_PATH = \"/kaggle/working/submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로컬 디렉토리 설정\n",
    "TRAIN_DIR = \"input/2025-csu-sw-ai-challenge/archive/train\" \n",
    "VAL_DIR = \"input/2025-csu-sw-ai-challenge/archive/val\"\n",
    "TEST_DIR = \"input/2025-csu-sw-ai-challenge/archive/test/images\"\n",
    "OUTPUT_CSV = \"working/submission.csv\" \n",
    "OUTPUT_MASK = \"working/mask_ouputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2025\n",
    "def set_seed(seed=SEED):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f'set SEED: {SEED}')\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.549403Z",
     "iopub.status.busy": "2025-10-13T11:27:22.549145Z",
     "iopub.status.idle": "2025-10-13T11:27:22.555503Z",
     "shell.execute_reply": "2025-10-13T11:27:22.554811Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.549387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CrackDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.img_dir = os.path.join(root_dir, \"images\")\n",
    "        self.mask_dir = os.path.join(root_dir, \"masks\")\n",
    "        self.img_list = sorted(glob.glob(self.img_dir + \"/*.jpg\"))\n",
    "        self.mask_list = sorted(glob.glob(self.mask_dir + \"/*.jpg\"))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.img_list[idx]).convert(\"L\")  # grayscale\n",
    "        mask = Image.open(self.mask_list[idx]).convert(\"L\")\n",
    "\n",
    "        img = np.array(img, dtype=np.float32) / 255.0\n",
    "        mask = np.array(mask, dtype=np.float32) / 255.0\n",
    "        mask = (mask > 0.5).astype(np.float32)  # binary mask\n",
    "\n",
    "        img = torch.tensor(img).unsqueeze(0)  # (1, H, W)\n",
    "        mask = torch.tensor(mask).unsqueeze(0)  # (1, H, W)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.557199Z",
     "iopub.status.busy": "2025-10-13T11:27:22.556966Z",
     "iopub.status.idle": "2025-10-13T11:27:22.580819Z",
     "shell.execute_reply": "2025-10-13T11:27:22.580155Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.557184Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HrSegNetB16(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=1,  # input channel\n",
    "                 base=16,  # base channel of the model, \n",
    "                 num_classes=1,  # number of classes\n",
    "                 pretrained=None  # pretrained model\n",
    "                 ):\n",
    "        super(HrSegNetB16, self).__init__()\n",
    "        self.base = base\n",
    "        self.num_classes = num_classes\n",
    "        self.pretrained = pretrained\n",
    "        # Stage 1 and 2 constitute the stem of the model, which is mainly used to extract low-level features.\n",
    "        # Meanwhile, stage1 and 2 reduce the input image to 1/2 and 1/4 of the original size respectively\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=base // 2, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(base // 2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.stage2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base // 2, out_channels=base, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(base),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.seg1 = SegBlock(base=base, stage_index=1)\n",
    "        self.seg2 = SegBlock(base=base, stage_index=2)\n",
    "        self.seg3 = SegBlock(base=base, stage_index=3)\n",
    "\n",
    "        self.aux_head1 = SegHead(inplanes=base, interplanes=base, outplanes=num_classes, aux_head=True)\n",
    "        self.aux_head2 = SegHead(inplanes=base, interplanes=base, outplanes=num_classes, aux_head=True)\n",
    "        self.head = SegHead(inplanes=base, interplanes=base, outplanes=num_classes)\n",
    "\n",
    "        self.init_weight()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logit_list = []\n",
    "        h, w = x.shape[2:]\n",
    "        # aux_head only used in training\n",
    "        if self.training:\n",
    "            stem1_out = self.stage1(x)\n",
    "            stem2_out = self.stage2(stem1_out)\n",
    "            hrseg1_out = self.seg1(stem2_out)\n",
    "            hrseg2_out = self.seg2(hrseg1_out)\n",
    "            hrseg3_out = self.seg3(hrseg2_out)\n",
    "            last_out = self.head(hrseg3_out)\n",
    "            seghead1_out = self.aux_head1(hrseg1_out)\n",
    "            seghead2_out = self.aux_head2(hrseg2_out)\n",
    "            logit_list = [last_out, seghead1_out, seghead2_out]\n",
    "            logit_list = [F.interpolate(logit, size=(h, w), mode='bilinear', align_corners=True) for logit in logit_list]\n",
    "            return logit_list\n",
    "        else:\n",
    "            stem1_out = self.stage1(x)\n",
    "            stem2_out = self.stage2(stem1_out)\n",
    "            hrseg1_out = self.seg1(stem2_out)\n",
    "            hrseg2_out = self.seg2(hrseg1_out)\n",
    "            hrseg3_out = self.seg3(hrseg2_out)\n",
    "            last_out = self.head(hrseg3_out)\n",
    "            logit_list = [last_out]\n",
    "            logit_list = [F.interpolate(logit, size=(h, w), mode='bilinear', align_corners=True) for logit in logit_list]\n",
    "            return logit_list\n",
    "        \n",
    "    \n",
    "    def init_weight(self):\n",
    "        if self.pretrained is not None:\n",
    "            pass\n",
    "        else:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    nn.init.kaiming_normal_(m.weight)\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "class SegBlock(nn.Module):\n",
    "    def __init__(self, base=32, stage_index=1):\n",
    "        super(SegBlock, self).__init__()\n",
    "\n",
    "        # Convolutional layer for high-resolution paths with constant spatial resolution and constant channel\n",
    "        self.h_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base, out_channels=base, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.h_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base, out_channels=base, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.h_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base, out_channels=base, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Semantic guidance path/low-resolution path\n",
    "        if stage_index == 1:  # First stage, stride=2, spatial resolution/2, channel*2\n",
    "            self.l_conv1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=base, out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        elif stage_index == 2:  # Second stage\n",
    "            self.l_conv1 = nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                nn.Conv2d(in_channels=base, out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        elif stage_index == 3:\n",
    "            self.l_conv1 = nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                nn.Conv2d(in_channels=base, out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"stage_index must be 1, 2 or 3\")\n",
    "        self.l_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.l2h_conv1 = nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base, kernel_size=1, stride=1, padding=0)\n",
    "        self.l2h_conv2 = nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base, kernel_size=1, stride=1, padding=0)\n",
    "        self.l2h_conv3 = nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        size = x.shape[2:]\n",
    "        out_h1 = self.h_conv1(x)  # high resolution path\n",
    "        out_l1 = self.l_conv1(x)  # low resolution path\n",
    "        out_l1_i = F.interpolate(out_l1, size=size, mode='bilinear', align_corners=True)  # upsample\n",
    "        out_hl1 = self.l2h_conv1(out_l1_i) + out_h1  # low to high\n",
    "\n",
    "        out_h2 = self.h_conv2(out_hl1)\n",
    "        out_l2 = self.l_conv2(out_l1)\n",
    "        out_l2_i = F.interpolate(out_l2, size=size, mode='bilinear', align_corners=True)\n",
    "        out_hl2 = self.l2h_conv2(out_l2_i) + out_h2\n",
    "\n",
    "        out_h3 = self.h_conv3(out_hl2)\n",
    "        out_l3 = self.l_conv3(out_l2)\n",
    "        out_l3_i = F.interpolate(out_l3, size=size, mode='bilinear', align_corners=True)\n",
    "        out_hl3 = self.l2h_conv3(out_l3_i) + out_h3\n",
    "        return out_hl3\n",
    "\n",
    "# seg head\n",
    "class SegHead(nn.Module):\n",
    "    def __init__(self, inplanes, interplanes, outplanes, aux_head=False):\n",
    "        super(SegHead, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.relu = nn.ReLU()\n",
    "        if aux_head:\n",
    "            self.con_bn_relu = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=inplanes, out_channels=interplanes, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(interplanes),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        else:\n",
    "            self.con_bn_relu = nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels=inplanes, out_channels=interplanes, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.BatchNorm2d(interplanes),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        self.conv = nn.Conv2d(in_channels=interplanes, out_channels=outplanes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.con_bn_relu(x)\n",
    "        out = self.conv(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.581758Z",
     "iopub.status.busy": "2025-10-13T11:27:22.581581Z",
     "iopub.status.idle": "2025-10-13T11:27:22.596935Z",
     "shell.execute_reply": "2025-10-13T11:27:22.596301Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.581742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def binary_metrics(preds, targets, eps=1e-6):\n",
    "    preds = preds.float()\n",
    "    targets = targets.float()\n",
    "\n",
    "    tp = (preds * targets).sum(dim=(1,2,3))\n",
    "    fp = (preds * (1 - targets)).sum(dim=(1,2,3))\n",
    "    fn = ((1 - preds) * targets).sum(dim=(1,2,3))\n",
    "\n",
    "    precision = (tp + eps) / (tp + fp + eps)\n",
    "    recall    = (tp + eps) / (tp + fn + eps)\n",
    "    f1        = (2 * precision * recall + eps) / (precision + recall + eps)  # Dice\n",
    "    union     = tp + fp + fn\n",
    "    iou       = (tp + eps) / (union + eps)\n",
    "\n",
    "    return {\n",
    "        \"iou\": iou.mean().item(),\n",
    "        \"precision\": precision.mean().item(),\n",
    "        \"recall\": recall.mean().item(),\n",
    "        \"f1\": f1.mean().item(),\n",
    "    }\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    epochs=10,\n",
    "    aux_weights=(1.0, 0.4, 0.4),\n",
    "    lr=1e-3,\n",
    "    use_amp=False,\n",
    "    log_every=500,\n",
    "    validate_every_steps=None,\n",
    "    threshold=0.5,):   \n",
    "    \n",
    "    model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "    global_step = 0\n",
    "    win_loss, win_iou, win_f1, win_steps = 0.0, 0.0, 0.0, 0\n",
    "    t0 = time.time()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for imgs, masks in train_loader:\n",
    "            global_step += 1\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            masks = masks.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                outputs = model(imgs)  # train: [main, aux1, aux2]\n",
    "                main_logit = outputs[0] if isinstance(outputs, (list, tuple)) else outputs\n",
    "                loss = aux_weights[0] * criterion(main_logit, masks)\n",
    "                if isinstance(outputs, (list, tuple)):\n",
    "                    if len(outputs) > 1 and aux_weights[1] > 0:\n",
    "                        loss = loss + aux_weights[1] * criterion(outputs[1], masks)\n",
    "                    if len(outputs) > 2 and aux_weights[2] > 0:\n",
    "                        loss = loss + aux_weights[2] * criterion(outputs[2], masks)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # 집계\n",
    "            epoch_loss += loss.item()\n",
    "            win_loss += loss.item()\n",
    "            win_steps += 1\n",
    "\n",
    "            with torch.no_grad():\n",
    "                probs = torch.sigmoid(main_logit)\n",
    "                preds = (probs > threshold).float()\n",
    "                m = binary_metrics(preds, masks)\n",
    "                win_iou += m[\"iou\"]\n",
    "                win_f1  += m[\"f1\"]\n",
    "\n",
    "            if log_every and (global_step % log_every == 0):\n",
    "                elapsed = time.time() - t0\n",
    "                lr_now = optimizer.param_groups[0][\"lr\"]\n",
    "                print(f\"[Step {global_step}] epoch={epoch}  \"\n",
    "                      f\"avg_loss(win)={win_loss/max(1,win_steps):.4f}  \"\n",
    "                      f\"avg_iou(win)={win_iou/max(1,win_steps):.4f}  \"\n",
    "                      f\"avg_f1(win)={win_f1/max(1,win_steps):.4f}  \"\n",
    "                      f\"lr={lr_now:.3e}  elapsed={elapsed:.1f}s\")\n",
    "                win_loss = win_iou = win_f1 = 0.0\n",
    "                win_steps = 0\n",
    "                t0 = time.time()\n",
    "\n",
    "            if validate_every_steps and (global_step % validate_every_steps == 0):\n",
    "                model.eval()\n",
    "                val_iou_list, val_f1_list = [], []\n",
    "                with torch.no_grad():\n",
    "                    for v_imgs, v_masks in val_loader:\n",
    "                        v_imgs = v_imgs.to(device, non_blocking=True)\n",
    "                        v_masks = v_masks.to(device, non_blocking=True)\n",
    "                        out_list = model(v_imgs)   # eval: [main]만\n",
    "                        main_logit_eval = out_list[0] if isinstance(out_list, (list, tuple)) else out_list\n",
    "                        preds = (torch.sigmoid(main_logit_eval) > threshold).float()\n",
    "                        m = binary_metrics(preds, v_masks)\n",
    "                        val_iou_list.append(m[\"iou\"])\n",
    "                        val_f1_list.append(m[\"f1\"])\n",
    "                print(f\"[Step {global_step}] 🔍 Val IoU={np.mean(val_iou_list):.4f} | Val F1={np.mean(val_f1_list):.4f}\")\n",
    "                model.train()\n",
    "\n",
    "        avg_train_loss = epoch_loss / max(1, len(train_loader))\n",
    "        model.eval()\n",
    "        val_iou_list, val_f1_list = [], []\n",
    "        with torch.no_grad():\n",
    "            for imgs, masks in val_loader:\n",
    "                imgs = imgs.to(device, non_blocking=True)\n",
    "                masks = masks.to(device, non_blocking=True)\n",
    "                logits_list = model(imgs)  # eval: [main]\n",
    "                main_logit = logits_list[0] if isinstance(logits_list, (list, tuple)) else logits_list\n",
    "                preds = (torch.sigmoid(main_logit) > threshold).float()\n",
    "                m = binary_metrics(preds, masks)\n",
    "                val_iou_list.append(m[\"iou\"])\n",
    "                val_f1_list.append(m[\"f1\"])\n",
    "        print(f\"[Epoch {epoch}/{epochs}] \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "              f\"Val IoU: {np.mean(val_iou_list):.4f} | \"\n",
    "              f\"Val F1: {np.mean(val_f1_list):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.597755Z",
     "iopub.status.busy": "2025-10-13T11:27:22.597539Z",
     "iopub.status.idle": "2025-10-13T11:27:22.853695Z",
     "shell.execute_reply": "2025-10-13T11:27:22.853224Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.597730Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = CrackDataset(TRAIN_DIR)\n",
    "val_dataset = CrackDataset(VAL_DIR)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.854526Z",
     "iopub.status.busy": "2025-10-13T11:27:22.854362Z",
     "iopub.status.idle": "2025-10-13T11:27:27.325732Z",
     "shell.execute_reply": "2025-10-13T11:27:27.324895Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.854513Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 609.75 k\n",
      "Total MACs: 130.86 MMac\n"
     ]
    }
   ],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HrSegNetB16().to(device)\n",
    "input_size = (1, 192, 192)\n",
    "\n",
    "macs, params = get_model_complexity_info(model,\n",
    "                                         input_size,\n",
    "                                         as_strings=True,\n",
    "                                         print_per_layer_stat=False,\n",
    "                                         verbose=False)\n",
    "print(f\"Total Params: {params}\")\n",
    "print(f\"Total MACs: {macs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:27.326740Z",
     "iopub.status.busy": "2025-10-13T11:27:27.326532Z",
     "iopub.status.idle": "2025-10-13T11:40:59.805475Z",
     "shell.execute_reply": "2025-10-13T11:40:59.804776Z",
     "shell.execute_reply.started": "2025-10-13T11:27:27.326723Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40006/3727572993.py:38: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
      "/tmp/ipykernel_40006/3727572993.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 500] epoch=1  avg_loss(win)=0.3772  avg_iou(win)=0.1780  avg_f1(win)=0.2556  lr=1.000e-03  elapsed=16.2s\n",
      "[Epoch 1/20] Train Loss: 0.2965 | Val IoU: 0.2858 | Val F1: 0.3961\n",
      "[Step 1000] epoch=2  avg_loss(win)=0.2023  avg_iou(win)=0.2417  avg_f1(win)=0.3545  lr=1.000e-03  elapsed=16.2s\n",
      "[Step 1500] epoch=2  avg_loss(win)=0.1702  avg_iou(win)=0.3231  avg_f1(win)=0.4492  lr=1.000e-03  elapsed=11.1s\n",
      "[Epoch 2/20] Train Loss: 0.1675 | Val IoU: 0.4130 | Val F1: 0.5398\n",
      "[Step 2000] epoch=3  avg_loss(win)=0.1607  avg_iou(win)=0.3590  avg_f1(win)=0.4831  lr=1.000e-03  elapsed=12.5s\n",
      "[Step 2500] epoch=3  avg_loss(win)=0.1496  avg_iou(win)=0.3837  avg_f1(win)=0.5092  lr=1.000e-03  elapsed=11.2s\n",
      "[Epoch 3/20] Train Loss: 0.1492 | Val IoU: 0.4234 | Val F1: 0.5486\n",
      "[Step 3000] epoch=4  avg_loss(win)=0.1468  avg_iou(win)=0.4075  avg_f1(win)=0.5318  lr=1.000e-03  elapsed=12.8s\n",
      "[Step 3500] epoch=4  avg_loss(win)=0.1376  avg_iou(win)=0.4151  avg_f1(win)=0.5392  lr=1.000e-03  elapsed=12.0s\n",
      "[Epoch 4/20] Train Loss: 0.1403 | Val IoU: 0.4693 | Val F1: 0.5966\n",
      "[Step 4000] epoch=5  avg_loss(win)=0.1403  avg_iou(win)=0.4271  avg_f1(win)=0.5498  lr=1.000e-03  elapsed=13.3s\n",
      "[Step 4500] epoch=5  avg_loss(win)=0.1356  avg_iou(win)=0.4467  avg_f1(win)=0.5684  lr=1.000e-03  elapsed=11.9s\n",
      "[Epoch 5/20] Train Loss: 0.1355 | Val IoU: 0.4646 | Val F1: 0.5821\n",
      "[Step 5000] epoch=6  avg_loss(win)=0.1312  avg_iou(win)=0.4532  avg_f1(win)=0.5765  lr=1.000e-03  elapsed=13.4s\n",
      "[Step 5500] epoch=6  avg_loss(win)=0.1300  avg_iou(win)=0.4624  avg_f1(win)=0.5854  lr=1.000e-03  elapsed=11.5s\n",
      "[Epoch 6/20] Train Loss: 0.1301 | Val IoU: 0.4837 | Val F1: 0.6017\n",
      "[Step 6000] epoch=7  avg_loss(win)=0.1274  avg_iou(win)=0.4645  avg_f1(win)=0.5862  lr=1.000e-03  elapsed=13.4s\n",
      "[Step 6500] epoch=7  avg_loss(win)=0.1275  avg_iou(win)=0.4668  avg_f1(win)=0.5902  lr=1.000e-03  elapsed=11.5s\n",
      "[Epoch 7/20] Train Loss: 0.1275 | Val IoU: 0.4917 | Val F1: 0.6104\n",
      "[Step 7000] epoch=8  avg_loss(win)=0.1275  avg_iou(win)=0.4742  avg_f1(win)=0.5961  lr=1.000e-03  elapsed=12.2s\n",
      "[Step 7500] epoch=8  avg_loss(win)=0.1239  avg_iou(win)=0.4826  avg_f1(win)=0.6059  lr=1.000e-03  elapsed=11.2s\n",
      "[Epoch 8/20] Train Loss: 0.1253 | Val IoU: 0.4861 | Val F1: 0.6042\n",
      "[Step 8000] epoch=9  avg_loss(win)=0.1217  avg_iou(win)=0.4784  avg_f1(win)=0.5993  lr=1.000e-03  elapsed=13.3s\n",
      "[Epoch 9/20] Train Loss: 0.1221 | Val IoU: 0.5030 | Val F1: 0.6222\n",
      "[Step 8500] epoch=10  avg_loss(win)=0.1231  avg_iou(win)=0.4933  avg_f1(win)=0.6152  lr=1.000e-03  elapsed=14.6s\n",
      "[Step 9000] epoch=10  avg_loss(win)=0.1197  avg_iou(win)=0.4964  avg_f1(win)=0.6204  lr=1.000e-03  elapsed=13.6s\n",
      "[Epoch 10/20] Train Loss: 0.1205 | Val IoU: 0.4911 | Val F1: 0.6080\n",
      "[Step 9500] epoch=11  avg_loss(win)=0.1214  avg_iou(win)=0.4901  avg_f1(win)=0.6133  lr=1.000e-03  elapsed=14.3s\n",
      "[Step 10000] epoch=11  avg_loss(win)=0.1187  avg_iou(win)=0.5040  avg_f1(win)=0.6256  lr=1.000e-03  elapsed=12.4s\n",
      "[Epoch 11/20] Train Loss: 0.1183 | Val IoU: 0.5234 | Val F1: 0.6436\n",
      "[Step 10500] epoch=12  avg_loss(win)=0.1177  avg_iou(win)=0.5041  avg_f1(win)=0.6265  lr=1.000e-03  elapsed=13.7s\n",
      "[Step 11000] epoch=12  avg_loss(win)=0.1154  avg_iou(win)=0.5105  avg_f1(win)=0.6332  lr=1.000e-03  elapsed=12.7s\n",
      "[Epoch 12/20] Train Loss: 0.1165 | Val IoU: 0.5231 | Val F1: 0.6425\n",
      "[Step 11500] epoch=13  avg_loss(win)=0.1176  avg_iou(win)=0.4987  avg_f1(win)=0.6201  lr=1.000e-03  elapsed=13.8s\n",
      "[Step 12000] epoch=13  avg_loss(win)=0.1148  avg_iou(win)=0.5098  avg_f1(win)=0.6312  lr=1.000e-03  elapsed=12.6s\n",
      "[Epoch 13/20] Train Loss: 0.1147 | Val IoU: 0.5041 | Val F1: 0.6242\n",
      "[Step 12500] epoch=14  avg_loss(win)=0.1113  avg_iou(win)=0.5145  avg_f1(win)=0.6351  lr=1.000e-03  elapsed=13.9s\n",
      "[Step 13000] epoch=14  avg_loss(win)=0.1173  avg_iou(win)=0.5116  avg_f1(win)=0.6339  lr=1.000e-03  elapsed=13.5s\n",
      "[Epoch 14/20] Train Loss: 0.1140 | Val IoU: 0.5334 | Val F1: 0.6557\n",
      "[Step 13500] epoch=15  avg_loss(win)=0.1111  avg_iou(win)=0.5186  avg_f1(win)=0.6415  lr=1.000e-03  elapsed=13.2s\n",
      "[Step 14000] epoch=15  avg_loss(win)=0.1105  avg_iou(win)=0.5251  avg_f1(win)=0.6485  lr=1.000e-03  elapsed=11.7s\n",
      "[Epoch 15/20] Train Loss: 0.1111 | Val IoU: 0.4705 | Val F1: 0.5937\n",
      "[Step 14500] epoch=16  avg_loss(win)=0.1106  avg_iou(win)=0.5221  avg_f1(win)=0.6463  lr=1.000e-03  elapsed=13.0s\n",
      "[Step 15000] epoch=16  avg_loss(win)=0.1106  avg_iou(win)=0.5182  avg_f1(win)=0.6412  lr=1.000e-03  elapsed=11.2s\n",
      "[Epoch 16/20] Train Loss: 0.1104 | Val IoU: 0.5153 | Val F1: 0.6358\n",
      "[Step 15500] epoch=17  avg_loss(win)=0.1074  avg_iou(win)=0.5419  avg_f1(win)=0.6621  lr=1.000e-03  elapsed=13.1s\n",
      "[Step 16000] epoch=17  avg_loss(win)=0.1092  avg_iou(win)=0.5276  avg_f1(win)=0.6508  lr=1.000e-03  elapsed=11.1s\n",
      "[Epoch 17/20] Train Loss: 0.1081 | Val IoU: 0.5144 | Val F1: 0.6379\n",
      "[Step 16500] epoch=18  avg_loss(win)=0.1077  avg_iou(win)=0.5346  avg_f1(win)=0.6550  lr=1.000e-03  elapsed=14.2s\n",
      "[Epoch 18/20] Train Loss: 0.1069 | Val IoU: 0.4981 | Val F1: 0.6250\n",
      "[Step 17000] epoch=19  avg_loss(win)=0.1066  avg_iou(win)=0.5350  avg_f1(win)=0.6575  lr=1.000e-03  elapsed=13.4s\n",
      "[Step 17500] epoch=19  avg_loss(win)=0.1034  avg_iou(win)=0.5478  avg_f1(win)=0.6703  lr=1.000e-03  elapsed=13.0s\n",
      "[Epoch 19/20] Train Loss: 0.1067 | Val IoU: 0.5084 | Val F1: 0.6283\n",
      "[Step 18000] epoch=20  avg_loss(win)=0.1091  avg_iou(win)=0.5293  avg_f1(win)=0.6479  lr=1.000e-03  elapsed=15.7s\n",
      "[Step 18500] epoch=20  avg_loss(win)=0.1051  avg_iou(win)=0.5410  avg_f1(win)=0.6636  lr=1.000e-03  elapsed=11.6s\n",
      "[Epoch 20/20] Train Loss: 0.1054 | Val IoU: 0.5008 | Val F1: 0.6233\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = HrSegNetB16().to(device)\n",
    "train_model(model, train_loader, val_loader, device, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mask_image(\n",
    "    mask_image: Image.Image,\n",
    "    base_output_dir: str,\n",
    "    original_filename: str,\n",
    "    script_name: str = 'defalut'\n",
    "):\n",
    "    \"\"\"\n",
    "    마스크 이미지를 지정된 규칙에 따라 폴더를 생성하고 저장합니다.\n",
    "\n",
    "    Args:\n",
    "        mask_image (Image.Image): 저장할 PIL 이미지 객체.\n",
    "        base_output_dir (str): 결과 폴더를 생성할 상위 경로.\n",
    "        original_filename (str): 원본 이미지 파일명 (e.g., 'image_001.jpg').\n",
    "        script_name (str): 현재 실행 중인 파이썬 스크립트 또는 노트북 파일명.\n",
    "    \n",
    "    Returns:\n",
    "        str: 파일이 저장된 전체 경로.\n",
    "    \"\"\"\n",
    "    # 1. 'test_파일명_mmddhhmm' 형식으로 폴더명 생성\n",
    "    now = datetime.datetime.now()\n",
    "    timestamp = now.strftime(\"%m%d%H%M\")  # mmddhhmm 형식\n",
    "    \n",
    "    # 스크립트 이름에서 확장자(.py, .ipynb) 제거\n",
    "    script_basename = os.path.splitext(script_name)[0]\n",
    "    \n",
    "    folder_name = f\"test_{script_basename}_{timestamp}\"\n",
    "    output_dir = os.path.join(base_output_dir, folder_name)\n",
    "    \n",
    "    # 폴더 생성 (이미 존재하면 그대로 사용)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 2. 저장할 파일명 생성 (원본 파일명 기반)\n",
    "    original_basename = os.path.splitext(original_filename)[0]\n",
    "    output_filename = f\"{original_basename}_mask.png\"\n",
    "    \n",
    "    # 3. 전체 저장 경로를 조합하고 이미지 저장\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    mask_image.save(output_path)\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:40:59.806608Z",
     "iopub.status.busy": "2025-10-13T11:40:59.806413Z",
     "iopub.status.idle": "2025-10-13T11:41:00.075814Z",
     "shell.execute_reply": "2025-10-13T11:41:00.075230Z",
     "shell.execute_reply.started": "2025-10-13T11:40:59.806593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def rle_encode(mask):\n",
    "    \"\"\"\n",
    "    mask: 2D numpy array of {0,1}, shape (H,W)\n",
    "    return: run length as string\n",
    "    \"\"\"\n",
    "    pixels = mask.flatten(order=\"C\")\n",
    "    ones = np.where(pixels == 1)[0] + 1  # 1-based\n",
    "    if len(ones) == 0:\n",
    "        return \"\"\n",
    "    runs = []\n",
    "    prev = -2\n",
    "    for idx in ones:\n",
    "        if idx > prev + 1:\n",
    "            runs.extend((idx, 0))\n",
    "        runs[-1] += 1\n",
    "        prev = idx\n",
    "    return \" \".join(map(str, runs))\n",
    "\n",
    "\n",
    "def predict_and_submit(model, test_img_dir, output_csv, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    ids, rles = [], []\n",
    "\n",
    "    test_imgs = sorted(glob.glob(os.path.join(test_img_dir, \"*.jpg\")))\n",
    "    for path in test_imgs:\n",
    "        img_id = os.path.splitext(os.path.basename(path))[0]\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "        arr = np.array(img, dtype=np.float32) / 255.0\n",
    "        tensor = torch.tensor(arr).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out_list = model(tensor)\n",
    "            main_logit = out_list[0] if isinstance(out_list, (list, tuple)) else out_list\n",
    "            prob = torch.sigmoid(main_logit)[0,0].cpu().numpy()\n",
    "            pred = (prob > threshold).astype(np.uint8)\n",
    "        \n",
    "        rle = rle_encode(pred)\n",
    "        ids.append(img_id)\n",
    "        rles.append(rle)\n",
    "\n",
    "    df = pd.DataFrame({\"image_id\": ids, \"rle\": rles})\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"[OK] submission saved to {output_csv}, total {len(df)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rle_encode(mask):\n",
    "    \"\"\"\n",
    "    mask: 2D numpy array of {0,1}, shape (H,W)\n",
    "    return: run length as string\n",
    "    \"\"\"\n",
    "    pixels = mask.flatten(order=\"C\")\n",
    "    ones = np.where(pixels == 1)[0] + 1  # 1-based\n",
    "    if len(ones) == 0:\n",
    "        return \"\"\n",
    "    runs = []\n",
    "    prev = -2\n",
    "    for idx in ones:\n",
    "        if idx > prev + 1:\n",
    "            runs.extend((idx, 0))\n",
    "        runs[-1] += 1\n",
    "        prev = idx\n",
    "    return \" \".join(map(str, runs))\n",
    "\n",
    "\n",
    "def predict_submit_and_save_masks(\n",
    "    model, \n",
    "    test_img_dir, \n",
    "    output_csv, \n",
    "    device, \n",
    "    threshold=0.5,\n",
    "    save_masks=False,\n",
    "    mask_save_dir=None\n",
    "):\n",
    "    \n",
    "    model.eval()\n",
    "    ids, rles = [], []\n",
    "\n",
    "    # --- 이미지 저장을 위한 폴더 설정 ---\n",
    "    output_mask_path = \"\"\n",
    "    if save_masks:\n",
    "        if mask_save_dir is None:\n",
    "            # mask_save_dir가 지정되지 않으면 에러 발생\n",
    "            raise ValueError(\"If save_masks is True, mask_save_dir must be provided.\")\n",
    "        \n",
    "        # 현재 시간을 기반으로 하위 폴더 생성\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_mask_path = os.path.join(mask_save_dir, f\"predictions_{timestamp}\")\n",
    "        os.makedirs(output_mask_path, exist_ok=True)\n",
    "        print(f\"Mask images will be saved to: {output_mask_path}\")\n",
    "\n",
    "    test_imgs = sorted(glob.glob(os.path.join(test_img_dir, \"*.jpg\")))\n",
    "    for path in test_imgs:\n",
    "        img_id = os.path.splitext(os.path.basename(path))[0]\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "        arr = np.array(img, dtype=np.float32) / 255.0\n",
    "        tensor = torch.tensor(arr).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out_list = model(tensor)\n",
    "            main_logit = out_list[0] if isinstance(out_list, (list, tuple)) else out_list\n",
    "            prob = torch.sigmoid(main_logit)[0,0].cpu().numpy()\n",
    "            pred = (prob > threshold).astype(np.uint8)\n",
    "        \n",
    "        # ---  마스크 이미지를 파일로 저장 ---\n",
    "        if save_masks:\n",
    "            mask_image = Image.fromarray(pred * 255, mode='L')\n",
    "            mask_filename = f\"{img_id}_mask.png\"\n",
    "            save_path = os.path.join(output_mask_path, mask_filename)\n",
    "            mask_image.save(save_path)\n",
    "\n",
    "        # --- RLE 인코딩 및 CSV 데이터 수집 ---\n",
    "        rle = rle_encode(pred)\n",
    "        ids.append(img_id)\n",
    "        rles.append(rle)\n",
    "\n",
    "    # --- CSV 파일로 최종 저장 ---\n",
    "    df = pd.DataFrame({\"image_id\": ids, \"rle\": rles})\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"OK. Submission CSV saved to {output_csv}, total {len(df)} rows.\")\n",
    "    \n",
    "    if save_masks:\n",
    "        print(f\"OK. Mask images also saved in: {output_mask_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:41:00.077800Z",
     "iopub.status.busy": "2025-10-13T11:41:00.077387Z",
     "iopub.status.idle": "2025-10-13T11:41:33.222667Z",
     "shell.execute_reply": "2025-10-13T11:41:33.222039Z",
     "shell.execute_reply.started": "2025-10-13T11:41:00.077781Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask images will be saved to: working/mask_ouputs/predictions_20251013_235632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40006/4196979983.py:61: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  mask_image = Image.fromarray(pred * 255, mode='L')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. Submission CSV saved to working/submission.csv, total 2667 rows.\n",
      "OK. Mask images also saved in: working/mask_ouputs/predictions_20251013_235632\n"
     ]
    }
   ],
   "source": [
    "predict_submit_and_save_masks(\n",
    "    model=model,\n",
    "    test_img_dir=TEST_DIR,\n",
    "    output_csv=\"working/submission.csv\",\n",
    "    device=device,\n",
    "    save_masks=True,  \n",
    "    mask_save_dir=OUTPUT_MASK\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13948799,
     "sourceId": 115856,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
