{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-13T11:26:07.826822Z",
     "iopub.status.busy": "2025-10-13T11:26:07.826549Z",
     "iopub.status.idle": "2025-10-13T11:27:16.075877Z",
     "shell.execute_reply": "2025-10-13T11:27:16.074947Z",
     "shell.execute_reply.started": "2025-10-13T11:26:07.826801Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install -q ptflops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:16.077527Z",
     "iopub.status.busy": "2025-10-13T11:27:16.077295Z",
     "iopub.status.idle": "2025-10-13T11:27:22.548576Z",
     "shell.execute_reply": "2025-10-13T11:27:22.548015Z",
     "shell.execute_reply.started": "2025-10-13T11:27:16.077501Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import jaccard_score\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import time\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 기본 디렉토리 설정 \n",
    "# TRAIN_DIR = \"/kaggle/input/2025-sw-ai/archive/train\"\n",
    "# VAL_DIR = \"/kaggle/input/2025-sw-ai/archive/val\"\n",
    "# TEST_DIR = \"/kaggle/input/2025-sw-ai/archive/test/images\"\n",
    "# OUTPUT_PATH = \"/kaggle/working/submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로컬 디렉토리 설정\n",
    "TRAIN_DIR = \"input/2025-csu-sw-ai-challenge/archive/train\" \n",
    "VAL_DIR = \"input/2025-csu-sw-ai-challenge/archive/val\"\n",
    "TEST_DIR = \"input/2025-csu-sw-ai-challenge/archive/test/images\"\n",
    "OUTPUT_CSV = \"working/submission.csv\" \n",
    "OUTPUT_MASK = \"working/mask_ouputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2025\n",
    "def set_seed(seed=SEED):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f'set SEED: {SEED}')\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.549403Z",
     "iopub.status.busy": "2025-10-13T11:27:22.549145Z",
     "iopub.status.idle": "2025-10-13T11:27:22.555503Z",
     "shell.execute_reply": "2025-10-13T11:27:22.554811Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.549387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CrackDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.img_dir = os.path.join(root_dir, \"images\")\n",
    "        self.mask_dir = os.path.join(root_dir, \"masks\")\n",
    "        self.img_list = sorted(glob.glob(self.img_dir + \"/*.jpg\"))\n",
    "        self.mask_list = sorted(glob.glob(self.mask_dir + \"/*.jpg\"))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.img_list[idx]).convert(\"L\")  # grayscale\n",
    "        mask = Image.open(self.mask_list[idx]).convert(\"L\")\n",
    "\n",
    "        img = np.array(img, dtype=np.float32) / 255.0\n",
    "        mask = np.array(mask, dtype=np.float32) / 255.0\n",
    "        mask = (mask > 0.5).astype(np.float32)  # binary mask\n",
    "\n",
    "        img = torch.tensor(img).unsqueeze(0)  # (1, H, W)\n",
    "        mask = torch.tensor(mask).unsqueeze(0)  # (1, H, W)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.557199Z",
     "iopub.status.busy": "2025-10-13T11:27:22.556966Z",
     "iopub.status.idle": "2025-10-13T11:27:22.580819Z",
     "shell.execute_reply": "2025-10-13T11:27:22.580155Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.557184Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HrSegNetB16(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=1,  # input channel\n",
    "                 base=16,  # base channel of the model, \n",
    "                 num_classes=1,  # number of classes\n",
    "                 pretrained=None  # pretrained model\n",
    "                 ):\n",
    "        super(HrSegNetB16, self).__init__()\n",
    "        self.base = base\n",
    "        self.num_classes = num_classes\n",
    "        self.pretrained = pretrained\n",
    "        # Stage 1 and 2 constitute the stem of the model, which is mainly used to extract low-level features.\n",
    "        # Meanwhile, stage1 and 2 reduce the input image to 1/2 and 1/4 of the original size respectively\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=base // 2, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(base // 2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.stage2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base // 2, out_channels=base, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(base),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.seg1 = SegBlock(base=base, stage_index=1)\n",
    "        self.seg2 = SegBlock(base=base, stage_index=2)\n",
    "        self.seg3 = SegBlock(base=base, stage_index=3)\n",
    "\n",
    "        self.aux_head1 = SegHead(inplanes=base, interplanes=base, outplanes=num_classes, aux_head=True)\n",
    "        self.aux_head2 = SegHead(inplanes=base, interplanes=base, outplanes=num_classes, aux_head=True)\n",
    "        self.head = SegHead(inplanes=base, interplanes=base, outplanes=num_classes)\n",
    "\n",
    "        self.init_weight()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logit_list = []\n",
    "        h, w = x.shape[2:]\n",
    "        # aux_head only used in training\n",
    "        if self.training:\n",
    "            stem1_out = self.stage1(x)\n",
    "            stem2_out = self.stage2(stem1_out)\n",
    "            hrseg1_out = self.seg1(stem2_out)\n",
    "            hrseg2_out = self.seg2(hrseg1_out)\n",
    "            hrseg3_out = self.seg3(hrseg2_out)\n",
    "            last_out = self.head(hrseg3_out)\n",
    "            seghead1_out = self.aux_head1(hrseg1_out)\n",
    "            seghead2_out = self.aux_head2(hrseg2_out)\n",
    "            logit_list = [last_out, seghead1_out, seghead2_out]\n",
    "            logit_list = [F.interpolate(logit, size=(h, w), mode='bilinear', align_corners=True) for logit in logit_list]\n",
    "            return logit_list\n",
    "        else:\n",
    "            stem1_out = self.stage1(x)\n",
    "            stem2_out = self.stage2(stem1_out)\n",
    "            hrseg1_out = self.seg1(stem2_out)\n",
    "            hrseg2_out = self.seg2(hrseg1_out)\n",
    "            hrseg3_out = self.seg3(hrseg2_out)\n",
    "            last_out = self.head(hrseg3_out)\n",
    "            logit_list = [last_out]\n",
    "            logit_list = [F.interpolate(logit, size=(h, w), mode='bilinear', align_corners=True) for logit in logit_list]\n",
    "            return logit_list\n",
    "        \n",
    "    \n",
    "    def init_weight(self):\n",
    "        if self.pretrained is not None:\n",
    "            pass\n",
    "        else:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    nn.init.kaiming_normal_(m.weight)\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "class SegBlock(nn.Module):\n",
    "    def __init__(self, base=32, stage_index=1):\n",
    "        super(SegBlock, self).__init__()\n",
    "\n",
    "        # Convolutional layer for high-resolution paths with constant spatial resolution and constant channel\n",
    "        self.h_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base, out_channels=base, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.h_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base, out_channels=base, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.h_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base, out_channels=base, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Semantic guidance path/low-resolution path\n",
    "        if stage_index == 1:  # First stage, stride=2, spatial resolution/2, channel*2\n",
    "            self.l_conv1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=base, out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        elif stage_index == 2:  # Second stage\n",
    "            self.l_conv1 = nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                nn.Conv2d(in_channels=base, out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        elif stage_index == 3:\n",
    "            self.l_conv1 = nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                nn.Conv2d(in_channels=base, out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"stage_index must be 1, 2 or 3\")\n",
    "        self.l_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.l2h_conv1 = nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base, kernel_size=1, stride=1, padding=0)\n",
    "        self.l2h_conv2 = nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base, kernel_size=1, stride=1, padding=0)\n",
    "        self.l2h_conv3 = nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        size = x.shape[2:]\n",
    "        out_h1 = self.h_conv1(x)  # high resolution path\n",
    "        out_l1 = self.l_conv1(x)  # low resolution path\n",
    "        out_l1_i = F.interpolate(out_l1, size=size, mode='bilinear', align_corners=True)  # upsample\n",
    "        out_hl1 = self.l2h_conv1(out_l1_i) + out_h1  # low to high\n",
    "\n",
    "        out_h2 = self.h_conv2(out_hl1)\n",
    "        out_l2 = self.l_conv2(out_l1)\n",
    "        out_l2_i = F.interpolate(out_l2, size=size, mode='bilinear', align_corners=True)\n",
    "        out_hl2 = self.l2h_conv2(out_l2_i) + out_h2\n",
    "\n",
    "        out_h3 = self.h_conv3(out_hl2)\n",
    "        out_l3 = self.l_conv3(out_l2)\n",
    "        out_l3_i = F.interpolate(out_l3, size=size, mode='bilinear', align_corners=True)\n",
    "        out_hl3 = self.l2h_conv3(out_l3_i) + out_h3\n",
    "        return out_hl3\n",
    "\n",
    "# seg head\n",
    "class SegHead(nn.Module):\n",
    "    def __init__(self, inplanes, interplanes, outplanes, aux_head=False):\n",
    "        super(SegHead, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.relu = nn.ReLU()\n",
    "        if aux_head:\n",
    "            self.con_bn_relu = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=inplanes, out_channels=interplanes, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(interplanes),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        else:\n",
    "            self.con_bn_relu = nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels=inplanes, out_channels=interplanes, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.BatchNorm2d(interplanes),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        self.conv = nn.Conv2d(in_channels=interplanes, out_channels=outplanes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.con_bn_relu(x)\n",
    "        out = self.conv(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.581758Z",
     "iopub.status.busy": "2025-10-13T11:27:22.581581Z",
     "iopub.status.idle": "2025-10-13T11:27:22.596935Z",
     "shell.execute_reply": "2025-10-13T11:27:22.596301Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.581742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def binary_metrics(preds, targets, eps=1e-6):\n",
    "    preds = preds.float()\n",
    "    targets = targets.float()\n",
    "\n",
    "    tp = (preds * targets).sum(dim=(1,2,3))\n",
    "    fp = (preds * (1 - targets)).sum(dim=(1,2,3))\n",
    "    fn = ((1 - preds) * targets).sum(dim=(1,2,3))\n",
    "\n",
    "    precision = (tp + eps) / (tp + fp + eps)\n",
    "    recall    = (tp + eps) / (tp + fn + eps)\n",
    "    f1        = (2 * precision * recall + eps) / (precision + recall + eps)  # Dice\n",
    "    union     = tp + fp + fn\n",
    "    iou       = (tp + eps) / (union + eps)\n",
    "\n",
    "    return {\n",
    "        \"iou\": iou.mean().item(),\n",
    "        \"precision\": precision.mean().item(),\n",
    "        \"recall\": recall.mean().item(),\n",
    "        \"f1\": f1.mean().item(),\n",
    "    }\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    epochs=10,\n",
    "    aux_weights=(1.0, 0.4, 0.4),\n",
    "    lr=1e-3,\n",
    "    use_amp=False,\n",
    "    log_every=500, # [복원] step 단위 로깅을 위해 원본 값 유지\n",
    "    validate_every_steps=None,\n",
    "    threshold=0.5,\n",
    "    patience=5, # [추가] Early Stopping을 위한 파라미터\n",
    "    model_save_path='best_model.pth' # [추가] Early Stopping을 위한 파라미터\n",
    "): \n",
    "    \n",
    "    model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "    # --- [추가] Early Stopping을 위한 변수 초기화 ---\n",
    "    patience_counter = 0\n",
    "    best_val_iou = 0.0\n",
    "    # --- [추가] Early Stopping 로직 끝 ---\n",
    "\n",
    "    global_step = 0\n",
    "    # --- [복원] Step 단위 로깅을 위한 변수 ---\n",
    "    win_loss, win_iou, win_f1, win_steps = 0.0, 0.0, 0.0, 0\n",
    "    t0 = time.time()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for imgs, masks in train_loader:\n",
    "            global_step += 1\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            masks = masks.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                outputs = model(imgs)\n",
    "                main_logit = outputs[0] if isinstance(outputs, (list, tuple)) else outputs\n",
    "                loss = aux_weights[0] * criterion(main_logit, masks)\n",
    "                if isinstance(outputs, (list, tuple)):\n",
    "                    if len(outputs) > 1 and aux_weights[1] > 0:\n",
    "                        loss = loss + aux_weights[1] * criterion(outputs[1], masks)\n",
    "                    if len(outputs) > 2 and aux_weights[2] > 0:\n",
    "                        loss = loss + aux_weights[2] * criterion(outputs[2], masks)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # --- [복원] Step 단위 로깅을 위한 집계 로직 ---\n",
    "            win_loss += loss.item()\n",
    "            win_steps += 1\n",
    "            with torch.no_grad():\n",
    "                probs = torch.sigmoid(main_logit)\n",
    "                preds = (probs > threshold).float()\n",
    "                m = binary_metrics(preds, masks)\n",
    "                win_iou += m[\"iou\"]\n",
    "                win_f1  += m[\"f1\"]\n",
    "            \n",
    "            # --- [복원] Step 단위 로깅 출력문 ---\n",
    "            if log_every and (global_step % log_every == 0):\n",
    "                elapsed = time.time() - t0\n",
    "                lr_now = optimizer.param_groups[0][\"lr\"]\n",
    "                print(f\"[Step {global_step}] epoch={epoch}  \"\n",
    "                      f\"avg_loss(win)={win_loss/max(1,win_steps):.4f}  \"\n",
    "                      f\"avg_iou(win)={win_iou/max(1,win_steps):.4f}  \"\n",
    "                      f\"avg_f1(win)={win_f1/max(1,win_steps):.4f}  \"\n",
    "                      f\"lr={lr_now:.3e}  elapsed={elapsed:.1f}s\")\n",
    "                win_loss = win_iou = win_f1 = 0.0\n",
    "                win_steps = 0\n",
    "                t0 = time.time()\n",
    "\n",
    "\n",
    "        # --- Epoch 종료 후 검증 단계 ---\n",
    "        avg_train_loss = epoch_loss / max(1, len(train_loader))\n",
    "        model.eval()\n",
    "        val_iou_list, val_f1_list, val_loss_list = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for imgs, masks in val_loader:\n",
    "                imgs = imgs.to(device, non_blocking=True)\n",
    "                masks = masks.to(device, non_blocking=True)\n",
    "                \n",
    "                logits_list = model(imgs)\n",
    "                main_logit = logits_list[0] if isinstance(logits_list, (list, tuple)) else logits_list\n",
    "                \n",
    "                loss = criterion(main_logit, masks)\n",
    "                val_loss_list.append(loss.item())\n",
    "\n",
    "                preds = (torch.sigmoid(main_logit) > threshold).float()\n",
    "                m = binary_metrics(preds, masks)\n",
    "                val_iou_list.append(m[\"iou\"])\n",
    "                val_f1_list.append(m[\"f1\"])\n",
    "\n",
    "        avg_val_loss = np.mean(val_loss_list)\n",
    "        avg_val_iou = np.mean(val_iou_list)\n",
    "        avg_val_f1 = np.mean(val_f1_list)\n",
    "        \n",
    "        # --- [복원] 원본 Epoch 단위 출력문 ---\n",
    "        print(f\"[Epoch {epoch}/{epochs}] \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f} | \"\n",
    "              f\"Val IoU: {avg_val_iou:.4f} | \"\n",
    "              f\"Val F1: {avg_val_f1:.4f}\")\n",
    "\n",
    "        # --- [추가] 간결한 Early Stopping 상태 출력 ---\n",
    "        if avg_val_iou > best_val_iou:\n",
    "            best_val_iou = avg_val_iou\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\" -> Best score updated. Model saved.\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\" -> Patience: {patience_counter}/{patience}\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered after {patience} epochs without improvement.\")\n",
    "            break\n",
    "        # --- [추가] Early Stopping 로직 끝 ---\n",
    "            \n",
    "    print(f\"\\nTraining finished. Best Val IoU was: {best_val_iou:.4f}\")\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.597755Z",
     "iopub.status.busy": "2025-10-13T11:27:22.597539Z",
     "iopub.status.idle": "2025-10-13T11:27:22.853695Z",
     "shell.execute_reply": "2025-10-13T11:27:22.853224Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.597730Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = CrackDataset(TRAIN_DIR)\n",
    "val_dataset = CrackDataset(VAL_DIR)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.854526Z",
     "iopub.status.busy": "2025-10-13T11:27:22.854362Z",
     "iopub.status.idle": "2025-10-13T11:27:27.325732Z",
     "shell.execute_reply": "2025-10-13T11:27:27.324895Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.854513Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HrSegNetB16().to(device)\n",
    "input_size = (1, 192, 192)\n",
    "\n",
    "macs, params = get_model_complexity_info(model,\n",
    "                                         input_size,\n",
    "                                         as_strings=True,\n",
    "                                         print_per_layer_stat=False,\n",
    "                                         verbose=False)\n",
    "print(f\"Total Params: {params}\")\n",
    "print(f\"Total MACs: {macs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:27.326740Z",
     "iopub.status.busy": "2025-10-13T11:27:27.326532Z",
     "iopub.status.idle": "2025-10-13T11:40:59.805475Z",
     "shell.execute_reply": "2025-10-13T11:40:59.804776Z",
     "shell.execute_reply.started": "2025-10-13T11:27:27.326723Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(device)\n",
    "train_model(model, train_loader, val_loader, device, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mask_image(\n",
    "    mask_image: Image.Image,\n",
    "    base_output_dir: str,\n",
    "    original_filename: str,\n",
    "    script_name: str = 'defalut'\n",
    "):\n",
    "    \"\"\"\n",
    "    마스크 이미지를 지정된 규칙에 따라 폴더를 생성하고 저장합니다.\n",
    "\n",
    "    Args:\n",
    "        mask_image (Image.Image): 저장할 PIL 이미지 객체.\n",
    "        base_output_dir (str): 결과 폴더를 생성할 상위 경로.\n",
    "        original_filename (str): 원본 이미지 파일명 (e.g., 'image_001.jpg').\n",
    "        script_name (str): 현재 실행 중인 파이썬 스크립트 또는 노트북 파일명.\n",
    "    \n",
    "    Returns:\n",
    "        str: 파일이 저장된 전체 경로.\n",
    "    \"\"\"\n",
    "    # 1. 'test_파일명_mmddhhmm' 형식으로 폴더명 생성\n",
    "    now = datetime.datetime.now()\n",
    "    timestamp = now.strftime(\"%m%d%H%M\")  # mmddhhmm 형식\n",
    "    \n",
    "    # 스크립트 이름에서 확장자(.py, .ipynb) 제거\n",
    "    script_basename = os.path.splitext(script_name)[0]\n",
    "    \n",
    "    folder_name = f\"test_{script_basename}_{timestamp}\"\n",
    "    output_dir = os.path.join(base_output_dir, folder_name)\n",
    "    \n",
    "    # 폴더 생성 (이미 존재하면 그대로 사용)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 2. 저장할 파일명 생성 (원본 파일명 기반)\n",
    "    original_basename = os.path.splitext(original_filename)[0]\n",
    "    output_filename = f\"{original_basename}_mask.png\"\n",
    "    \n",
    "    # 3. 전체 저장 경로를 조합하고 이미지 저장\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    mask_image.save(output_path)\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:40:59.806608Z",
     "iopub.status.busy": "2025-10-13T11:40:59.806413Z",
     "iopub.status.idle": "2025-10-13T11:41:00.075814Z",
     "shell.execute_reply": "2025-10-13T11:41:00.075230Z",
     "shell.execute_reply.started": "2025-10-13T11:40:59.806593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def rle_encode(mask):\n",
    "    \"\"\"\n",
    "    mask: 2D numpy array of {0,1}, shape (H,W)\n",
    "    return: run length as string\n",
    "    \"\"\"\n",
    "    pixels = mask.flatten(order=\"C\")\n",
    "    ones = np.where(pixels == 1)[0] + 1  # 1-based\n",
    "    if len(ones) == 0:\n",
    "        return \"\"\n",
    "    runs = []\n",
    "    prev = -2\n",
    "    for idx in ones:\n",
    "        if idx > prev + 1:\n",
    "            runs.extend((idx, 0))\n",
    "        runs[-1] += 1\n",
    "        prev = idx\n",
    "    return \" \".join(map(str, runs))\n",
    "\n",
    "\n",
    "def predict_and_submit(model, test_img_dir, output_csv, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    ids, rles = [], []\n",
    "\n",
    "    test_imgs = sorted(glob.glob(os.path.join(test_img_dir, \"*.jpg\")))\n",
    "    for path in test_imgs:\n",
    "        img_id = os.path.splitext(os.path.basename(path))[0]\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "        arr = np.array(img, dtype=np.float32) / 255.0\n",
    "        tensor = torch.tensor(arr).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out_list = model(tensor)\n",
    "            main_logit = out_list[0] if isinstance(out_list, (list, tuple)) else out_list\n",
    "            prob = torch.sigmoid(main_logit)[0,0].cpu().numpy()\n",
    "            pred = (prob > threshold).astype(np.uint8)\n",
    "        \n",
    "        rle = rle_encode(pred)\n",
    "        ids.append(img_id)\n",
    "        rles.append(rle)\n",
    "\n",
    "    df = pd.DataFrame({\"image_id\": ids, \"rle\": rles})\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"[OK] submission saved to {output_csv}, total {len(df)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rle_encode(mask):\n",
    "    \"\"\"\n",
    "    mask: 2D numpy array of {0,1}, shape (H,W)\n",
    "    return: run length as string\n",
    "    \"\"\"\n",
    "    pixels = mask.flatten(order=\"C\")\n",
    "    ones = np.where(pixels == 1)[0] + 1  # 1-based\n",
    "    if len(ones) == 0:\n",
    "        return \"\"\n",
    "    runs = []\n",
    "    prev = -2\n",
    "    for idx in ones:\n",
    "        if idx > prev + 1:\n",
    "            runs.extend((idx, 0))\n",
    "        runs[-1] += 1\n",
    "        prev = idx\n",
    "    return \" \".join(map(str, runs))\n",
    "\n",
    "\n",
    "def predict_submit_and_save_masks(\n",
    "    model, \n",
    "    test_img_dir, \n",
    "    output_csv, \n",
    "    device, \n",
    "    threshold=0.5,\n",
    "    save_masks=False,\n",
    "    mask_save_dir=None\n",
    "):\n",
    "    \n",
    "    model.eval()\n",
    "    ids, rles = [], []\n",
    "\n",
    "    # --- 이미지 저장을 위한 폴더 설정 ---\n",
    "    output_mask_path = \"\"\n",
    "    if save_masks:\n",
    "        if mask_save_dir is None:\n",
    "            # mask_save_dir가 지정되지 않으면 에러 발생\n",
    "            raise ValueError(\"If save_masks is True, mask_save_dir must be provided.\")\n",
    "        \n",
    "        # 현재 시간을 기반으로 하위 폴더 생성\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_mask_path = os.path.join(mask_save_dir, f\"predictions_{timestamp}\")\n",
    "        os.makedirs(output_mask_path, exist_ok=True)\n",
    "        print(f\"Mask images will be saved to: {output_mask_path}\")\n",
    "\n",
    "    test_imgs = sorted(glob.glob(os.path.join(test_img_dir, \"*.jpg\")))\n",
    "    for path in test_imgs:\n",
    "        img_id = os.path.splitext(os.path.basename(path))[0]\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "        arr = np.array(img, dtype=np.float32) / 255.0\n",
    "        tensor = torch.tensor(arr).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out_list = model(tensor)\n",
    "            main_logit = out_list[0] if isinstance(out_list, (list, tuple)) else out_list\n",
    "            prob = torch.sigmoid(main_logit)[0,0].cpu().numpy()\n",
    "            pred = (prob > threshold).astype(np.uint8)\n",
    "        \n",
    "        # ---  마스크 이미지를 파일로 저장 ---\n",
    "        if save_masks:\n",
    "            mask_image = Image.fromarray(pred * 255, mode='L')\n",
    "            mask_filename = f\"{img_id}_mask.png\"\n",
    "            save_path = os.path.join(output_mask_path, mask_filename)\n",
    "            mask_image.save(save_path)\n",
    "\n",
    "        # --- RLE 인코딩 및 CSV 데이터 수집 ---\n",
    "        rle = rle_encode(pred)\n",
    "        ids.append(img_id)\n",
    "        rles.append(rle)\n",
    "\n",
    "    # --- CSV 파일로 최종 저장 ---\n",
    "    df = pd.DataFrame({\"image_id\": ids, \"rle\": rles})\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"OK. Submission CSV saved to {output_csv}, total {len(df)} rows.\")\n",
    "    \n",
    "    if save_masks:\n",
    "        print(f\"OK. Mask images also saved in: {output_mask_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:41:00.077800Z",
     "iopub.status.busy": "2025-10-13T11:41:00.077387Z",
     "iopub.status.idle": "2025-10-13T11:41:33.222667Z",
     "shell.execute_reply": "2025-10-13T11:41:33.222039Z",
     "shell.execute_reply.started": "2025-10-13T11:41:00.077781Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predict_submit_and_save_masks(\n",
    "    model=model,\n",
    "    test_img_dir=TEST_DIR,\n",
    "    output_csv=\"working/submission.csv\",\n",
    "    device=device,\n",
    "    save_masks=True,  \n",
    "    mask_save_dir=OUTPUT_MASK\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13948799,
     "sourceId": 115856,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
