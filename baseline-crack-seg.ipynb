{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-13T11:26:07.826822Z",
     "iopub.status.busy": "2025-10-13T11:26:07.826549Z",
     "iopub.status.idle": "2025-10-13T11:27:16.075877Z",
     "shell.execute_reply": "2025-10-13T11:27:16.074947Z",
     "shell.execute_reply.started": "2025-10-13T11:26:07.826801Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install -q ptflops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:16.077527Z",
     "iopub.status.busy": "2025-10-13T11:27:16.077295Z",
     "iopub.status.idle": "2025-10-13T11:27:22.548576Z",
     "shell.execute_reply": "2025-10-13T11:27:22.548015Z",
     "shell.execute_reply.started": "2025-10-13T11:27:16.077501Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import jaccard_score\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ê¸°ë³¸ ë””ë ‰í† ë¦¬ ì„¤ì • \n",
    "# TRAIN_DIR = \"/kaggle/input/2025-sw-ai/archive/train\"\n",
    "# VAL_DIR = \"/kaggle/input/2025-sw-ai/archive/val\"\n",
    "# TEST_DIR = \"/kaggle/input/2025-sw-ai/archive/test/images\"\n",
    "# OUTPUT_PATH = \"/kaggle/working/submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¡œì»¬ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "TRAIN_DIR = \"input/2025-csu-sw-ai-challenge/archive/train\" \n",
    "VAL_DIR = \"input/2025-csu-sw-ai-challenge/archive/val\"\n",
    "TEST_DIR = \"input/2025-csu-sw-ai-challenge/archive/test/images\"\n",
    "OUTPUT_PATH = \"working/submission.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.549403Z",
     "iopub.status.busy": "2025-10-13T11:27:22.549145Z",
     "iopub.status.idle": "2025-10-13T11:27:22.555503Z",
     "shell.execute_reply": "2025-10-13T11:27:22.554811Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.549387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CrackDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.img_dir = os.path.join(root_dir, \"images\")\n",
    "        self.mask_dir = os.path.join(root_dir, \"masks\")\n",
    "        self.img_list = sorted(glob.glob(self.img_dir + \"/*.jpg\"))\n",
    "        self.mask_list = sorted(glob.glob(self.mask_dir + \"/*.jpg\"))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.img_list[idx]).convert(\"L\")  # grayscale\n",
    "        mask = Image.open(self.mask_list[idx]).convert(\"L\")\n",
    "\n",
    "        img = np.array(img, dtype=np.float32) / 255.0\n",
    "        mask = np.array(mask, dtype=np.float32) / 255.0\n",
    "        mask = (mask > 0.5).astype(np.float32)  # binary mask\n",
    "\n",
    "        img = torch.tensor(img).unsqueeze(0)  # (1, H, W)\n",
    "        mask = torch.tensor(mask).unsqueeze(0)  # (1, H, W)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.557199Z",
     "iopub.status.busy": "2025-10-13T11:27:22.556966Z",
     "iopub.status.idle": "2025-10-13T11:27:22.580819Z",
     "shell.execute_reply": "2025-10-13T11:27:22.580155Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.557184Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HrSegNetB16(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=1,  # input channel\n",
    "                 base=16,  # base channel of the model, \n",
    "                 num_classes=1,  # number of classes\n",
    "                 pretrained=None  # pretrained model\n",
    "                 ):\n",
    "        super(HrSegNetB16, self).__init__()\n",
    "        self.base = base\n",
    "        self.num_classes = num_classes\n",
    "        self.pretrained = pretrained\n",
    "        # Stage 1 and 2 constitute the stem of the model, which is mainly used to extract low-level features.\n",
    "        # Meanwhile, stage1 and 2 reduce the input image to 1/2 and 1/4 of the original size respectively\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=base // 2, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(base // 2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.stage2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base // 2, out_channels=base, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(base),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.seg1 = SegBlock(base=base, stage_index=1)\n",
    "        self.seg2 = SegBlock(base=base, stage_index=2)\n",
    "        self.seg3 = SegBlock(base=base, stage_index=3)\n",
    "\n",
    "        self.aux_head1 = SegHead(inplanes=base, interplanes=base, outplanes=num_classes, aux_head=True)\n",
    "        self.aux_head2 = SegHead(inplanes=base, interplanes=base, outplanes=num_classes, aux_head=True)\n",
    "        self.head = SegHead(inplanes=base, interplanes=base, outplanes=num_classes)\n",
    "\n",
    "        self.init_weight()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logit_list = []\n",
    "        h, w = x.shape[2:]\n",
    "        # aux_head only used in training\n",
    "        if self.training:\n",
    "            stem1_out = self.stage1(x)\n",
    "            stem2_out = self.stage2(stem1_out)\n",
    "            hrseg1_out = self.seg1(stem2_out)\n",
    "            hrseg2_out = self.seg2(hrseg1_out)\n",
    "            hrseg3_out = self.seg3(hrseg2_out)\n",
    "            last_out = self.head(hrseg3_out)\n",
    "            seghead1_out = self.aux_head1(hrseg1_out)\n",
    "            seghead2_out = self.aux_head2(hrseg2_out)\n",
    "            logit_list = [last_out, seghead1_out, seghead2_out]\n",
    "            logit_list = [F.interpolate(logit, size=(h, w), mode='bilinear', align_corners=True) for logit in logit_list]\n",
    "            return logit_list\n",
    "        else:\n",
    "            stem1_out = self.stage1(x)\n",
    "            stem2_out = self.stage2(stem1_out)\n",
    "            hrseg1_out = self.seg1(stem2_out)\n",
    "            hrseg2_out = self.seg2(hrseg1_out)\n",
    "            hrseg3_out = self.seg3(hrseg2_out)\n",
    "            last_out = self.head(hrseg3_out)\n",
    "            logit_list = [last_out]\n",
    "            logit_list = [F.interpolate(logit, size=(h, w), mode='bilinear', align_corners=True) for logit in logit_list]\n",
    "            return logit_list\n",
    "        \n",
    "    \n",
    "    def init_weight(self):\n",
    "        if self.pretrained is not None:\n",
    "            pass\n",
    "        else:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    nn.init.kaiming_normal_(m.weight)\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "class SegBlock(nn.Module):\n",
    "    def __init__(self, base=32, stage_index=1):\n",
    "        super(SegBlock, self).__init__()\n",
    "\n",
    "        # Convolutional layer for high-resolution paths with constant spatial resolution and constant channel\n",
    "        self.h_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base, out_channels=base, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.h_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base, out_channels=base, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.h_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base, out_channels=base, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Semantic guidance path/low-resolution path\n",
    "        if stage_index == 1:  # First stage, stride=2, spatial resolution/2, channel*2\n",
    "            self.l_conv1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=base, out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        elif stage_index == 2:  # Second stage\n",
    "            self.l_conv1 = nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                nn.Conv2d(in_channels=base, out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        elif stage_index == 3:\n",
    "            self.l_conv1 = nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                nn.Conv2d(in_channels=base, out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"stage_index must be 1, 2 or 3\")\n",
    "        self.l_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base * int(math.pow(2, stage_index)), kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(base * int(math.pow(2, stage_index))),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.l2h_conv1 = nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base, kernel_size=1, stride=1, padding=0)\n",
    "        self.l2h_conv2 = nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base, kernel_size=1, stride=1, padding=0)\n",
    "        self.l2h_conv3 = nn.Conv2d(in_channels=base * int(math.pow(2, stage_index)), out_channels=base, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        size = x.shape[2:]\n",
    "        out_h1 = self.h_conv1(x)  # high resolution path\n",
    "        out_l1 = self.l_conv1(x)  # low resolution path\n",
    "        out_l1_i = F.interpolate(out_l1, size=size, mode='bilinear', align_corners=True)  # upsample\n",
    "        out_hl1 = self.l2h_conv1(out_l1_i) + out_h1  # low to high\n",
    "\n",
    "        out_h2 = self.h_conv2(out_hl1)\n",
    "        out_l2 = self.l_conv2(out_l1)\n",
    "        out_l2_i = F.interpolate(out_l2, size=size, mode='bilinear', align_corners=True)\n",
    "        out_hl2 = self.l2h_conv2(out_l2_i) + out_h2\n",
    "\n",
    "        out_h3 = self.h_conv3(out_hl2)\n",
    "        out_l3 = self.l_conv3(out_l2)\n",
    "        out_l3_i = F.interpolate(out_l3, size=size, mode='bilinear', align_corners=True)\n",
    "        out_hl3 = self.l2h_conv3(out_l3_i) + out_h3\n",
    "        return out_hl3\n",
    "\n",
    "# seg head\n",
    "class SegHead(nn.Module):\n",
    "    def __init__(self, inplanes, interplanes, outplanes, aux_head=False):\n",
    "        super(SegHead, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.relu = nn.ReLU()\n",
    "        if aux_head:\n",
    "            self.con_bn_relu = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=inplanes, out_channels=interplanes, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(interplanes),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        else:\n",
    "            self.con_bn_relu = nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels=inplanes, out_channels=interplanes, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.BatchNorm2d(interplanes),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        self.conv = nn.Conv2d(in_channels=interplanes, out_channels=outplanes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.con_bn_relu(x)\n",
    "        out = self.conv(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.581758Z",
     "iopub.status.busy": "2025-10-13T11:27:22.581581Z",
     "iopub.status.idle": "2025-10-13T11:27:22.596935Z",
     "shell.execute_reply": "2025-10-13T11:27:22.596301Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.581742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def binary_metrics(preds, targets, eps=1e-6):\n",
    "    preds = preds.float()\n",
    "    targets = targets.float()\n",
    "\n",
    "    tp = (preds * targets).sum(dim=(1,2,3))\n",
    "    fp = (preds * (1 - targets)).sum(dim=(1,2,3))\n",
    "    fn = ((1 - preds) * targets).sum(dim=(1,2,3))\n",
    "\n",
    "    precision = (tp + eps) / (tp + fp + eps)\n",
    "    recall    = (tp + eps) / (tp + fn + eps)\n",
    "    f1        = (2 * precision * recall + eps) / (precision + recall + eps)  # Dice\n",
    "    union     = tp + fp + fn\n",
    "    iou       = (tp + eps) / (union + eps)\n",
    "\n",
    "    return {\n",
    "        \"iou\": iou.mean().item(),\n",
    "        \"precision\": precision.mean().item(),\n",
    "        \"recall\": recall.mean().item(),\n",
    "        \"f1\": f1.mean().item(),\n",
    "    }\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    epochs=10,\n",
    "    aux_weights=(1.0, 0.4, 0.4),\n",
    "    lr=1e-3,\n",
    "    use_amp=False,\n",
    "    log_every=500,\n",
    "    validate_every_steps=None,\n",
    "    threshold=0.5,):   \n",
    "    \n",
    "    model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "    global_step = 0\n",
    "    win_loss, win_iou, win_f1, win_steps = 0.0, 0.0, 0.0, 0\n",
    "    t0 = time.time()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for imgs, masks in train_loader:\n",
    "            global_step += 1\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            masks = masks.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                outputs = model(imgs)  # train: [main, aux1, aux2]\n",
    "                main_logit = outputs[0] if isinstance(outputs, (list, tuple)) else outputs\n",
    "                loss = aux_weights[0] * criterion(main_logit, masks)\n",
    "                if isinstance(outputs, (list, tuple)):\n",
    "                    if len(outputs) > 1 and aux_weights[1] > 0:\n",
    "                        loss = loss + aux_weights[1] * criterion(outputs[1], masks)\n",
    "                    if len(outputs) > 2 and aux_weights[2] > 0:\n",
    "                        loss = loss + aux_weights[2] * criterion(outputs[2], masks)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # ì§‘ê³„\n",
    "            epoch_loss += loss.item()\n",
    "            win_loss += loss.item()\n",
    "            win_steps += 1\n",
    "\n",
    "            with torch.no_grad():\n",
    "                probs = torch.sigmoid(main_logit)\n",
    "                preds = (probs > threshold).float()\n",
    "                m = binary_metrics(preds, masks)\n",
    "                win_iou += m[\"iou\"]\n",
    "                win_f1  += m[\"f1\"]\n",
    "\n",
    "            if log_every and (global_step % log_every == 0):\n",
    "                elapsed = time.time() - t0\n",
    "                lr_now = optimizer.param_groups[0][\"lr\"]\n",
    "                print(f\"[Step {global_step}] epoch={epoch}  \"\n",
    "                      f\"avg_loss(win)={win_loss/max(1,win_steps):.4f}  \"\n",
    "                      f\"avg_iou(win)={win_iou/max(1,win_steps):.4f}  \"\n",
    "                      f\"avg_f1(win)={win_f1/max(1,win_steps):.4f}  \"\n",
    "                      f\"lr={lr_now:.3e}  elapsed={elapsed:.1f}s\")\n",
    "                win_loss = win_iou = win_f1 = 0.0\n",
    "                win_steps = 0\n",
    "                t0 = time.time()\n",
    "\n",
    "            if validate_every_steps and (global_step % validate_every_steps == 0):\n",
    "                model.eval()\n",
    "                val_iou_list, val_f1_list = [], []\n",
    "                with torch.no_grad():\n",
    "                    for v_imgs, v_masks in val_loader:\n",
    "                        v_imgs = v_imgs.to(device, non_blocking=True)\n",
    "                        v_masks = v_masks.to(device, non_blocking=True)\n",
    "                        out_list = model(v_imgs)   # eval: [main]ë§Œ\n",
    "                        main_logit_eval = out_list[0] if isinstance(out_list, (list, tuple)) else out_list\n",
    "                        preds = (torch.sigmoid(main_logit_eval) > threshold).float()\n",
    "                        m = binary_metrics(preds, v_masks)\n",
    "                        val_iou_list.append(m[\"iou\"])\n",
    "                        val_f1_list.append(m[\"f1\"])\n",
    "                print(f\"[Step {global_step}] ðŸ” Val IoU={np.mean(val_iou_list):.4f} | Val F1={np.mean(val_f1_list):.4f}\")\n",
    "                model.train()\n",
    "\n",
    "        avg_train_loss = epoch_loss / max(1, len(train_loader))\n",
    "        model.eval()\n",
    "        val_iou_list, val_f1_list = [], []\n",
    "        with torch.no_grad():\n",
    "            for imgs, masks in val_loader:\n",
    "                imgs = imgs.to(device, non_blocking=True)\n",
    "                masks = masks.to(device, non_blocking=True)\n",
    "                logits_list = model(imgs)  # eval: [main]\n",
    "                main_logit = logits_list[0] if isinstance(logits_list, (list, tuple)) else logits_list\n",
    "                preds = (torch.sigmoid(main_logit) > threshold).float()\n",
    "                m = binary_metrics(preds, masks)\n",
    "                val_iou_list.append(m[\"iou\"])\n",
    "                val_f1_list.append(m[\"f1\"])\n",
    "        print(f\"[Epoch {epoch}/{epochs}] \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "              f\"Val IoU: {np.mean(val_iou_list):.4f} | \"\n",
    "              f\"Val F1: {np.mean(val_f1_list):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.597755Z",
     "iopub.status.busy": "2025-10-13T11:27:22.597539Z",
     "iopub.status.idle": "2025-10-13T11:27:22.853695Z",
     "shell.execute_reply": "2025-10-13T11:27:22.853224Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.597730Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = CrackDataset(TRAIN_DIR)\n",
    "val_dataset = CrackDataset(VAL_DIR)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:22.854526Z",
     "iopub.status.busy": "2025-10-13T11:27:22.854362Z",
     "iopub.status.idle": "2025-10-13T11:27:27.325732Z",
     "shell.execute_reply": "2025-10-13T11:27:27.324895Z",
     "shell.execute_reply.started": "2025-10-13T11:27:22.854513Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 609.75 k\n",
      "Total MACs: 130.86 MMac\n"
     ]
    }
   ],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HrSegNetB16().to(device)\n",
    "input_size = (1, 192, 192)\n",
    "\n",
    "macs, params = get_model_complexity_info(model,\n",
    "                                         input_size,\n",
    "                                         as_strings=True,\n",
    "                                         print_per_layer_stat=False,\n",
    "                                         verbose=False)\n",
    "print(f\"Total Params: {params}\")\n",
    "print(f\"Total MACs: {macs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:27:27.326740Z",
     "iopub.status.busy": "2025-10-13T11:27:27.326532Z",
     "iopub.status.idle": "2025-10-13T11:40:59.805475Z",
     "shell.execute_reply": "2025-10-13T11:40:59.804776Z",
     "shell.execute_reply.started": "2025-10-13T11:27:27.326723Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40006/3727572993.py:38: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
      "/tmp/ipykernel_40006/3727572993.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 500] epoch=1  avg_loss(win)=0.4380  avg_iou(win)=0.1449  avg_f1(win)=0.2039  lr=1.000e-03  elapsed=11.9s\n",
      "[Epoch 1/20] Train Loss: 0.3325 | Val IoU: 0.2190 | Val F1: 0.2992\n",
      "[Step 1000] epoch=2  avg_loss(win)=0.2131  avg_iou(win)=0.2169  avg_f1(win)=0.3190  lr=1.000e-03  elapsed=13.3s\n",
      "[Step 1500] epoch=2  avg_loss(win)=0.1799  avg_iou(win)=0.2699  avg_f1(win)=0.3956  lr=1.000e-03  elapsed=11.5s\n",
      "[Epoch 2/20] Train Loss: 0.1765 | Val IoU: 0.3537 | Val F1: 0.4636\n",
      "[Step 2000] epoch=3  avg_loss(win)=0.1650  avg_iou(win)=0.3298  avg_f1(win)=0.4610  lr=1.000e-03  elapsed=12.6s\n",
      "[Step 2500] epoch=3  avg_loss(win)=0.1599  avg_iou(win)=0.3619  avg_f1(win)=0.4914  lr=1.000e-03  elapsed=11.9s\n",
      "[Epoch 3/20] Train Loss: 0.1569 | Val IoU: 0.4195 | Val F1: 0.5370\n",
      "[Step 3000] epoch=4  avg_loss(win)=0.1489  avg_iou(win)=0.3838  avg_f1(win)=0.5094  lr=1.000e-03  elapsed=13.7s\n",
      "[Step 3500] epoch=4  avg_loss(win)=0.1497  avg_iou(win)=0.3914  avg_f1(win)=0.5146  lr=1.000e-03  elapsed=11.1s\n",
      "[Epoch 4/20] Train Loss: 0.1482 | Val IoU: 0.4512 | Val F1: 0.5677\n",
      "[Step 4000] epoch=5  avg_loss(win)=0.1485  avg_iou(win)=0.4032  avg_f1(win)=0.5254  lr=1.000e-03  elapsed=11.9s\n",
      "[Step 4500] epoch=5  avg_loss(win)=0.1410  avg_iou(win)=0.4139  avg_f1(win)=0.5391  lr=1.000e-03  elapsed=10.6s\n",
      "[Epoch 5/20] Train Loss: 0.1415 | Val IoU: 0.4645 | Val F1: 0.5857\n",
      "[Step 5000] epoch=6  avg_loss(win)=0.1392  avg_iou(win)=0.4300  avg_f1(win)=0.5562  lr=1.000e-03  elapsed=12.3s\n",
      "[Step 5500] epoch=6  avg_loss(win)=0.1340  avg_iou(win)=0.4410  avg_f1(win)=0.5650  lr=1.000e-03  elapsed=11.0s\n",
      "[Epoch 6/20] Train Loss: 0.1365 | Val IoU: 0.4489 | Val F1: 0.5710\n",
      "[Step 6000] epoch=7  avg_loss(win)=0.1355  avg_iou(win)=0.4437  avg_f1(win)=0.5659  lr=1.000e-03  elapsed=12.7s\n",
      "[Step 6500] epoch=7  avg_loss(win)=0.1343  avg_iou(win)=0.4471  avg_f1(win)=0.5686  lr=1.000e-03  elapsed=11.9s\n",
      "[Epoch 7/20] Train Loss: 0.1339 | Val IoU: 0.4670 | Val F1: 0.5861\n",
      "[Step 7000] epoch=8  avg_loss(win)=0.1274  avg_iou(win)=0.4564  avg_f1(win)=0.5812  lr=1.000e-03  elapsed=12.9s\n",
      "[Step 7500] epoch=8  avg_loss(win)=0.1318  avg_iou(win)=0.4632  avg_f1(win)=0.5856  lr=1.000e-03  elapsed=11.8s\n",
      "[Epoch 8/20] Train Loss: 0.1294 | Val IoU: 0.4916 | Val F1: 0.6122\n",
      "[Step 8000] epoch=9  avg_loss(win)=0.1266  avg_iou(win)=0.4652  avg_f1(win)=0.5893  lr=1.000e-03  elapsed=15.1s\n",
      "[Epoch 9/20] Train Loss: 0.1282 | Val IoU: 0.5016 | Val F1: 0.6245\n",
      "[Step 8500] epoch=10  avg_loss(win)=0.1293  avg_iou(win)=0.4703  avg_f1(win)=0.5879  lr=1.000e-03  elapsed=17.1s\n",
      "[Step 9000] epoch=10  avg_loss(win)=0.1265  avg_iou(win)=0.4775  avg_f1(win)=0.5985  lr=1.000e-03  elapsed=15.8s\n",
      "[Epoch 10/20] Train Loss: 0.1253 | Val IoU: 0.4704 | Val F1: 0.5857\n",
      "[Step 9500] epoch=11  avg_loss(win)=0.1242  avg_iou(win)=0.4834  avg_f1(win)=0.6052  lr=1.000e-03  elapsed=14.4s\n",
      "[Step 10000] epoch=11  avg_loss(win)=0.1236  avg_iou(win)=0.4873  avg_f1(win)=0.6097  lr=1.000e-03  elapsed=13.2s\n",
      "[Epoch 11/20] Train Loss: 0.1232 | Val IoU: 0.4975 | Val F1: 0.6185\n",
      "[Step 10500] epoch=12  avg_loss(win)=0.1200  avg_iou(win)=0.4822  avg_f1(win)=0.6042  lr=1.000e-03  elapsed=15.3s\n",
      "[Step 11000] epoch=12  avg_loss(win)=0.1249  avg_iou(win)=0.4817  avg_f1(win)=0.6058  lr=1.000e-03  elapsed=14.5s\n",
      "[Epoch 12/20] Train Loss: 0.1214 | Val IoU: 0.4394 | Val F1: 0.5551\n",
      "[Step 11500] epoch=13  avg_loss(win)=0.1201  avg_iou(win)=0.4923  avg_f1(win)=0.6134  lr=1.000e-03  elapsed=15.1s\n",
      "[Step 12000] epoch=13  avg_loss(win)=0.1168  avg_iou(win)=0.4997  avg_f1(win)=0.6196  lr=1.000e-03  elapsed=13.1s\n",
      "[Epoch 13/20] Train Loss: 0.1193 | Val IoU: 0.5097 | Val F1: 0.6326\n",
      "[Step 12500] epoch=14  avg_loss(win)=0.1195  avg_iou(win)=0.5007  avg_f1(win)=0.6223  lr=1.000e-03  elapsed=13.5s\n",
      "[Step 13000] epoch=14  avg_loss(win)=0.1179  avg_iou(win)=0.5087  avg_f1(win)=0.6305  lr=1.000e-03  elapsed=11.3s\n",
      "[Epoch 14/20] Train Loss: 0.1176 | Val IoU: 0.5216 | Val F1: 0.6389\n",
      "[Step 13500] epoch=15  avg_loss(win)=0.1179  avg_iou(win)=0.5059  avg_f1(win)=0.6294  lr=1.000e-03  elapsed=13.2s\n",
      "[Step 14000] epoch=15  avg_loss(win)=0.1144  avg_iou(win)=0.5096  avg_f1(win)=0.6306  lr=1.000e-03  elapsed=13.5s\n",
      "[Epoch 15/20] Train Loss: 0.1159 | Val IoU: 0.5346 | Val F1: 0.6573\n",
      "[Step 14500] epoch=16  avg_loss(win)=0.1122  avg_iou(win)=0.5184  avg_f1(win)=0.6395  lr=1.000e-03  elapsed=13.2s\n",
      "[Step 15000] epoch=16  avg_loss(win)=0.1183  avg_iou(win)=0.5042  avg_f1(win)=0.6262  lr=1.000e-03  elapsed=11.5s\n",
      "[Epoch 16/20] Train Loss: 0.1148 | Val IoU: 0.4707 | Val F1: 0.5900\n",
      "[Step 15500] epoch=17  avg_loss(win)=0.1128  avg_iou(win)=0.5204  avg_f1(win)=0.6402  lr=1.000e-03  elapsed=12.6s\n",
      "[Step 16000] epoch=17  avg_loss(win)=0.1111  avg_iou(win)=0.5252  avg_f1(win)=0.6469  lr=1.000e-03  elapsed=12.0s\n",
      "[Epoch 17/20] Train Loss: 0.1115 | Val IoU: 0.5211 | Val F1: 0.6396\n",
      "[Step 16500] epoch=18  avg_loss(win)=0.1108  avg_iou(win)=0.5232  avg_f1(win)=0.6460  lr=1.000e-03  elapsed=13.4s\n",
      "[Epoch 18/20] Train Loss: 0.1114 | Val IoU: 0.5263 | Val F1: 0.6473\n",
      "[Step 17000] epoch=19  avg_loss(win)=0.1119  avg_iou(win)=0.5165  avg_f1(win)=0.6367  lr=1.000e-03  elapsed=13.4s\n",
      "[Step 17500] epoch=19  avg_loss(win)=0.1081  avg_iou(win)=0.5279  avg_f1(win)=0.6496  lr=1.000e-03  elapsed=12.2s\n",
      "[Epoch 19/20] Train Loss: 0.1093 | Val IoU: 0.5052 | Val F1: 0.6301\n",
      "[Step 18000] epoch=20  avg_loss(win)=0.1104  avg_iou(win)=0.5293  avg_f1(win)=0.6490  lr=1.000e-03  elapsed=13.3s\n",
      "[Step 18500] epoch=20  avg_loss(win)=0.1083  avg_iou(win)=0.5371  avg_f1(win)=0.6584  lr=1.000e-03  elapsed=11.4s\n",
      "[Epoch 20/20] Train Loss: 0.1086 | Val IoU: 0.5161 | Val F1: 0.6398\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = HrSegNetB16().to(device)\n",
    "train_model(model, train_loader, val_loader, device, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:40:59.806608Z",
     "iopub.status.busy": "2025-10-13T11:40:59.806413Z",
     "iopub.status.idle": "2025-10-13T11:41:00.075814Z",
     "shell.execute_reply": "2025-10-13T11:41:00.075230Z",
     "shell.execute_reply.started": "2025-10-13T11:40:59.806593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def rle_encode(mask):\n",
    "    \"\"\"\n",
    "    mask: 2D numpy array of {0,1}, shape (H,W)\n",
    "    return: run length as string\n",
    "    \"\"\"\n",
    "    pixels = mask.flatten(order=\"C\")\n",
    "    ones = np.where(pixels == 1)[0] + 1  # 1-based\n",
    "    if len(ones) == 0:\n",
    "        return \"\"\n",
    "    runs = []\n",
    "    prev = -2\n",
    "    for idx in ones:\n",
    "        if idx > prev + 1:\n",
    "            runs.extend((idx, 0))\n",
    "        runs[-1] += 1\n",
    "        prev = idx\n",
    "    return \" \".join(map(str, runs))\n",
    "\n",
    "\n",
    "def predict_and_submit(model, test_img_dir, output_csv, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    ids, rles = [], []\n",
    "\n",
    "    test_imgs = sorted(glob.glob(os.path.join(test_img_dir, \"*.jpg\")))\n",
    "    for path in test_imgs:\n",
    "        img_id = os.path.splitext(os.path.basename(path))[0]\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "        arr = np.array(img, dtype=np.float32) / 255.0\n",
    "        tensor = torch.tensor(arr).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out_list = model(tensor)\n",
    "            main_logit = out_list[0] if isinstance(out_list, (list, tuple)) else out_list\n",
    "            prob = torch.sigmoid(main_logit)[0,0].cpu().numpy()\n",
    "            pred = (prob > threshold).astype(np.uint8)\n",
    "\n",
    "        rle = rle_encode(pred)\n",
    "        ids.append(img_id)\n",
    "        rles.append(rle)\n",
    "\n",
    "    df = pd.DataFrame({\"image_id\": ids, \"rle\": rles})\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"[OK] submission saved to {output_csv}, total {len(df)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:41:00.077800Z",
     "iopub.status.busy": "2025-10-13T11:41:00.077387Z",
     "iopub.status.idle": "2025-10-13T11:41:33.222667Z",
     "shell.execute_reply": "2025-10-13T11:41:33.222039Z",
     "shell.execute_reply.started": "2025-10-13T11:41:00.077781Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] submission saved to working/submission.csv, total 2667 rows.\n"
     ]
    }
   ],
   "source": [
    "predict_and_submit(\n",
    "    model, \n",
    "    test_img_dir=TEST_DIR,\n",
    "    output_csv=OUTPUT_PATH,\n",
    "    device=device,\n",
    "    threshold=0.5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13948799,
     "sourceId": 115856,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
